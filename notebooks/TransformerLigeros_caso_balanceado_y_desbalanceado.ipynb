{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYq6vxzWCeN5l41B1NF65u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjl-ai/TFM-Sentimiento-Politico-Transformers/blob/main/notebooks/TransformerLigeros_caso_balanceado_y_desbalanceado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ C√ìDIGO 1 (COLAB) ‚Äî DESBALANCEADO\n",
        "\n",
        "Copia y pega tal cual en una celda (o en varias, pero es un solo script)."
      ],
      "metadata": {
        "id": "ZmBFCOsrrMR4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6H98uA7gOyn"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# TFM - NLP Sentimiento Pol√≠tico (Transformers ligeros)\n",
        "# NOTEBOOK 1/2: DESBALANCEADO\n",
        "# Google Colab - transformers==4.44.2\n",
        "#\n",
        "# Entrenamiento SOLO con:\n",
        "#   - text_tr         (normalizado con tildes, preserva contexto)\n",
        "#   - text_tr_noacc   (normalizado sin tildes)\n",
        "#\n",
        "# EDA (solo an√°lisis):\n",
        "#   - EDA agresivo (stopwords+limpieza fuerte) para TF-IDF / Chi2 / WordCloud\n",
        "#   - TF-IDF y Chi2: filtra t√©rminos {\"marca\",\"numero\",\"n√∫mero\",\"escribe\"}\n",
        "#\n",
        "# ZIP: incluye SOLO lo necesario para el TFM (PNG, CSV, MD, TXT, JSON)\n",
        "#     NO incluye checkpoints pesados -> evita errores de memoria\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install -U \"transformers==4.44.2\" datasets evaluate accelerate scikit-learn wordcloud ftfy\n",
        "\n",
        "import os, re, json, gc, random, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from ftfy import fix_text\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
        "    set_seed, EarlyStoppingCallback\n",
        ")\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1) CONFIG\n",
        "# ---------------------------\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/danielalva2008/TFM/master/TFM_UNIR/DATASETS/2.-Dataset%20Trabajados/data_extended.csv\"\n",
        "\n",
        "SCENARIO = \"desbalanceado\"\n",
        "ZIP_NAME = \"TFM_Desbalanceado_outputs.zip\"\n",
        "\n",
        "OUTPUT_DIR = \"/content/outputs_desbalanceado\"\n",
        "FIG_DIR    = os.path.join(OUTPUT_DIR, \"figures\")\n",
        "REP_DIR    = os.path.join(OUTPUT_DIR, \"reports\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "os.makedirs(REP_DIR, exist_ok=True)\n",
        "\n",
        "MODELS = {\n",
        "    \"DistilBERT-es\": \"dccuchile/distilbert-base-spanish-uncased\",\n",
        "    \"ALBETO Tiny\": \"dccuchile/albert-tiny-spanish\",\n",
        "    \"MiniLM Multilingual\": \"microsoft/Multilingual-MiniLM-L12-H384\",\n",
        "}\n",
        "\n",
        "TEXT_COL  = \"full_text\"\n",
        "LABEL_COL = \"label\"\n",
        "LABEL_NAME = {0: \"negativo\", 1: \"neutro\", 2: \"positivo\"}\n",
        "VALID_LABELS = set(LABEL_NAME.keys())\n",
        "\n",
        "# Colores por clase (barras)\n",
        "CLASS_COLORS = {0: \"red\", 1: \"gray\", 2: \"green\"}\n",
        "\n",
        "# Entrenamiento\n",
        "MAX_LEN = 128\n",
        "TEST_SIZE = 0.15\n",
        "VAL_SIZE  = 0.15\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "GRAD_ACC = 1\n",
        "#TARGET_EFFECTIVE_BATCH = 32           # <- ajusta si deseas\n",
        "#GRAD_ACC = max(1, TARGET_EFFECTIVE_BATCH // BATCH_SIZE)\n",
        "\n",
        "EPOCHS = 4\n",
        "LR = 2e-5\n",
        "USE_FP16 = torch.cuda.is_available()\n",
        "EARLY_STOPPING_PATIENCE = 2\n",
        "\n",
        "# Solo 2 variantes para entrenamiento (lo que pediste)\n",
        "TEXT_VARIANTS_FOR_TRAIN = [\"text_tr\", \"text_tr_noacc\"]\n",
        "\n",
        "# Filtro solicitado SOLO para TF-IDF/Chi2\n",
        "TFIDF_CHI2_BANNED = {\"marca\", \"numero\", \"n√∫mero\", \"escribe\"}\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2) HELPERS\n",
        "# ---------------------------\n",
        "def clear_gpu():\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def save_fig(path):\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def fix_text_utf8(s: str) -> str:\n",
        "    return fix_text(str(s))\n",
        "\n",
        "def remove_accents(text: str) -> str:\n",
        "    # equivalente al enfoque de DIACRITICAL_VOWELS (Alva)\n",
        "    pairs = [('√°','a'), ('√©','e'), ('√≠','i'), ('√≥','o'), ('√∫','u'), ('√º','u')]\n",
        "    t = str(text)\n",
        "    for a, b in pairs:\n",
        "        t = t.replace(a, b).replace(a.upper(), b.upper())\n",
        "    return t\n",
        "\n",
        "# ---------------------------\n",
        "# 3) SLANG + STOPWORDS (Alva + ajuste mrd)\n",
        "# ---------------------------\n",
        "SLANG = [\n",
        "    (r\"\\bmrd\\b\", \"mierda\"),\n",
        "    (r\"\\bd\\b\", \"de\"),\n",
        "    (r\"\\b[qk]\\b\", \"que\"),\n",
        "    (r\"\\bxo\\b\", \"pero\"),\n",
        "    (r\"\\bxa\\b\", \"para\"),\n",
        "    (r\"\\b[xp]q\\b\", \"porque\"),\n",
        "    (r\"\\bes[qk]\\b\", \"es que\"),\n",
        "    (r\"\\bfvr\\b\", \"favor\"),\n",
        "    (r\"\\b(xfa|xf|pf|plis|pls|porfa)\\b\", \"por favor\"),\n",
        "    (r\"\\bdnd\\b\", \"donde\"),\n",
        "    (r\"\\btb\\b\", \"tambi√©n\"),\n",
        "    (r\"\\b(tq|tk)\\b\", \"te quiero\"),\n",
        "    (r\"\\b(tqm|tkm)\\b\", \"te quiero mucho\"),\n",
        "    (r\"\\bx\\b\", \"por\"),\n",
        "    (r\"\\+\", \"mas\"),\n",
        "    (r\"\\bpi√±a\\b\", \"mala suerte\"),\n",
        "    (r\"\\bagarre\\b\", \"adulterio\"),\n",
        "    (r\"\\bampay\\b\", \"verguenza\"),\n",
        "    (r\"\\bbacan\\b\", \"alegria\"),\n",
        "    (r\"\\bbamba\\b\", \"falsificado\"),\n",
        "    (r\"\\bcabeceador\\b\", \"ladron\"),\n",
        "    (r\"\\bcabro\\b\", \"homosexual\"),\n",
        "    (r\"\\bcachaciento\\b\", \"burlon\"),\n",
        "    (r\"\\bcalabacita\\b\", \"tonta\"),\n",
        "    (r\"\\bcaleta\\b\", \"secreto\"),\n",
        "    (r\"\\bcana\\b\", \"carcel\"),\n",
        "    (r\"\\bchucha\\b\", \"molestia\"),\n",
        "    (r\"\\bchoro\\b\", \"ladron\"),\n",
        "    (r\"\\bconch√°n\\b\", \"conchudo\"),\n",
        "    (r\"\\bcutra\\b\", \"ilicito\"),\n",
        "    (r\"\\bdark\\b\", \"horrible\"),\n",
        "    (r\"\\blenteja\\b\", \"torpe\"),\n",
        "    (r\"\\blorna\\b\", \"tonto\"),\n",
        "    (r\"\\bmancar\\b\", \"morir\"),\n",
        "    (r\"\\bmonse\\b\", \"tonto\"),\n",
        "    (r\"\\bpi√±ata\\b\", \"mala suerte\"),\n",
        "]\n",
        "\n",
        "# Stopwords (lista grande de Alva). Mantengo la idea: se usa SOLO en EDA agresivo.\n",
        "# Nota: no las uso en entrenamiento transformers.\n",
        "stop_words = set([\n",
        "    'a', 'adelante', 'adem√°s', 'afirm√≥', 'agreg√≥', 'ahi', 'ahora', 'ah√≠', 'al',\n",
        "    'algo', 'alguna', 'algunas', 'alguno', 'algunos', 'alg√∫n', 'alrededor', 'ambos',\n",
        "    'ampleamos', 'ante', 'anterior', 'antes', 'apenas', 'aproximadamente', 'aquel',\n",
        "    'aquellas', 'aquellos', 'aqui', 'aqu√≠', 'arriba', 'as', 'asegur√≥', 'asi', 'as√≠',\n",
        "    'atras', 'aunque', 'a√∫n', 'ayer', 'b', 'bajo', 'bastante', 'bien', 'buen',\n",
        "    'buena', 'buenas', 'bueno', 'buenos', 'c', 'cada', 'casi', 'cc', 'cerca',\n",
        "    'cierta', 'ciertas', 'cierto', 'ciertos', 'cinco', 'coment√≥', 'como', 'con',\n",
        "    'conocer', 'conseguimos', 'conseguir', 'considera', 'consider√≥', 'consigue',\n",
        "    'consiguen', 'consigues', 'consigo', 'contra', 'cosas', 'creo', 'cual',\n",
        "    'cuales', 'cualquier', 'cuando', 'cuanto', 'cuatro', 'cuenta', 'c√≥mo', 'd',\n",
        "    'da', 'dado', 'dan', 'dar', 'de', 'debe', 'deben', 'debido', 'decir', 'dej√≥',\n",
        "    'del', 'dem√°s', 'dentro', 'desde', 'despu√©s', 'dia', 'dice', 'dicen', 'dicho',\n",
        "    'dieron', 'diferente', 'diferentes', 'dijeron', 'dijo', 'dio', 'do', 'don',\n",
        "    'donde', 'dos', 'durante', 'e', 'ejemplo', 'el', 'ella', 'ellas', 'ello',\n",
        "    'ellos', 'embargo', 'empleais', 'emplean', 'emplear', 'empleas', 'empleo',\n",
        "    'en', 'encima', 'encuentra', 'entonces', 'entre', 'era', 'eramos', 'eran',\n",
        "    'eras', 'eres', 'es', 'esa', 'esas', 'ese', 'eso', 'esos', 'esta', 'estaba',\n",
        "    'estaban', 'estado', 'estais', 'estamos', 'estan', 'estar', 'estar√°', 'estas',\n",
        "    'este', 'esto', 'estos', 'estoy', 'estuvo', 'ex', 'existe', 'existen',\n",
        "    'explic√≥', 'expres√≥', 'f', 'fin', 'fue', 'fuera', 'fueron', 'fui', 'fuimos',\n",
        "    'g', 'gran', 'grandes', 'gueno', 'h', 'ha', 'haber', 'hab√≠a', 'hab√≠an',\n",
        "    'habr√°', 'hace', 'haceis', 'hacemos', 'hacen', 'hacer', 'hacerlo', 'haces',\n",
        "    'hacia', 'haciendo', 'hago', 'han', 'has', 'hasta', 'hay', 'haya', 'he',\n",
        "    'hecho', 'hemos', 'hicieron', 'hizo', 'hoy', 'hubo', 'i', 'igual', 'incluso',\n",
        "    'indic√≥', 'inform√≥', 'intenta', 'intentais', 'intentamos', 'intentan',\n",
        "    'intentar', 'intentas', 'intento', 'ir', 'is', 'j', 'junto', 'k', 'l', 'la',\n",
        "    'lado', 'largo', 'las', 'le', 'les', 'lleg√≥', 'lleva', 'llevar', 'lo', 'los',\n",
        "    'luego', 'lugar', 'm', 'manera', 'manifest√≥', 'mas', 'mayor', 'me', 'mediante',\n",
        "    'mejor', 'mencion√≥', 'menos', 'mi', 'mientras', 'mio', 'mis', 'misma',\n",
        "    'mismas', 'mismo', 'mismos', 'mo', 'modo', 'momento', 'mucha', 'muchas',\n",
        "    'mucho', 'muchos', 'muy', 'm√°s', 'n', 'nada', 'nadie', 'ni', 'ninguna',\n",
        "    'ningunas', 'ninguno', 'ningunos', 'ning√∫n', 'nos', 'nosotras', 'nosotros',\n",
        "    'nuestra', 'nuestras', 'nuestro', 'nuestros', 'nueva', 'nuevas', 'nuevo',\n",
        "    'nuevos', 'nunca', 'o', 'ocho', 'of', 'otra', 'otras', 'otro', 'otros',\n",
        "    'p', 'pa', 'para', 'parece', 'parte', 'partir', 'pasada', 'pasado', 'pero',\n",
        "    'pesar', 'poca', 'pocas', 'poco', 'pocos', 'podeis', 'podemos', 'poder',\n",
        "    'podra', 'podr√°n', 'podria', 'podriais', 'podriamos', 'podrian', 'podrias',\n",
        "    'podr√≠a', 'podr√≠an', 'poner', 'por', 'porque', 'por qu√©', 'posible', 'pq',\n",
        "    'primer', 'primera', 'primero', 'primeros', 'principalmente', 'propia',\n",
        "    'propias', 'propio', 'propios', 'pr√≥ximo', 'pr√≥ximos', 'pt', 'pudo', 'pueda',\n",
        "    'puede', 'pueden', 'puedo', 'pues', 'q', 'qie', 'qu', 'que', 'qued√≥',\n",
        "    'queremos', 'quien', 'quienes', 'quiere', 'qu√©', 'qui√©n', 'r', 'realizado',\n",
        "    'realizar', 'realiz√≥', 'respecto', 's', 'sabe', 'sabeis', 'sabemos', 'saben',\n",
        "    'saber', 'sabes', 'se', 'sea', 'sean', 'segunda', 'segundo', 'seg√∫n', 'seis',\n",
        "    'sera', 'ser√°', 'ser√°n', 'ser√≠a', 'si', 'sido', 'siempre', 'siendo', 'siete',\n",
        "    'sigue', 'siguiente', 'sin', 'sino', 'sobre', 'sois', 'sola', 'solamente',\n",
        "    'solas', 'solo', 'solos', 'somos', 'son', 'soy', 'su', 'sua', 'sus', 's√≠',\n",
        "    's√≥lo', 'se√±al√≥', 't', 'tal', 'tambi√©n', 'tampoco', 'tan', 'tanto', 'te',\n",
        "    'tendr√°', 'tendr√°n', 'teneis', 'tenemos', 'tener', 'tenga', 'tengo', 'ten√≠a',\n",
        "    'tenido', 'tercera', 'the', 'ti', 'tiempo', 'tiene', 'tienen', 'to', 'toda',\n",
        "    'todas', 'todav√≠a', 'todo', 'todos', 'total', 'trabaja', 'trabajais',\n",
        "    'trabajamos', 'trabajan', 'trabajar', 'trabajas', 'trabajo', 'tras',\n",
        "    'trata', 'trav√©s', 'tres', 'tu', 'tus', 'tuvo', 'tuyo', 'u', 'un', 'una',\n",
        "    'unas', 'uno', 'unos', 'us', 'usa', 'usais', 'usamos', 'usan', 'usar',\n",
        "    'usas', 'uso', 'usted', 'v', 'va', 'vais', 'valor', 'vamos', 'van',\n",
        "    'varias', 'varios', 'vaya', 'veces', 'ven', 'ver', 'verdad', 'verdadera',\n",
        "    'verdadero', 'vez', 'via', 'vosotras', 'vosotros', 'voy', 'w', 'x', 'y',\n",
        "    'ya', 'yo', 'z', '√°', '√©sta', '√©ste', '√©stas', '√©stos', '√∫ltima', '√∫ltimas',\n",
        "    'ultimo', '√∫ltimo', '√∫ltimos'\n",
        "])\n",
        "\n",
        "\n",
        "def apply_slang(t: str) -> str:\n",
        "    for pat, rep in SLANG:\n",
        "        t = re.sub(pat, rep, t)\n",
        "    return t\n",
        "\n",
        "# ---------------------------\n",
        "# 4) TEXTO PARA ENTRENAMIENTO (preserva contexto)\n",
        "# ---------------------------\n",
        "def normalize_for_transformer(text: str, remove_tilde: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Normalizaci√≥n suave:\n",
        "    - corrige mojibake (ftfy)\n",
        "    - baja a min√∫sculas\n",
        "    - quita URLs, @menciones, #hashtags\n",
        "    - aplica SLANG (incluye mrd->mierda)\n",
        "    - limpia caracteres raros PERO conserva tildes/√±\n",
        "    - NO elimina stopwords (para preservar contexto)\n",
        "    \"\"\"\n",
        "    t = fix_text_utf8(text).lower()\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\w+\", \" \", t)\n",
        "    t = re.sub(r\"#\\w+\", \" \", t)\n",
        "    t = apply_slang(t)\n",
        "\n",
        "    # deja letras + tildes + √± + espacios\n",
        "    t = re.sub(r\"[^a-z√°√©√≠√≥√∫√±√º\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "    if remove_tilde:\n",
        "        t = remove_accents(t)\n",
        "        t = re.sub(r\"[^a-z√±\\s]\", \" \", t)\n",
        "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "    return t\n",
        "\n",
        "# ---------------------------\n",
        "# 5) TEXTO PARA EDA (agresivo, solo an√°lisis)\n",
        "# ---------------------------\n",
        "def eda_aggressive(text: str) -> str:\n",
        "    \"\"\"\n",
        "    EDA agresivo:\n",
        "    - corrige mojibake\n",
        "    - sin tildes\n",
        "    - quita URLs/@/# y s√≠mbolos\n",
        "    - aplica SLANG\n",
        "    - elimina stopwords\n",
        "    \"\"\"\n",
        "    t = fix_text_utf8(text).lower()\n",
        "    t = apply_slang(t)\n",
        "    t = remove_accents(t)\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\w+\", \" \", t)\n",
        "    t = re.sub(r\"#\\w+\", \" \", t)\n",
        "    t = re.sub(r\"[^a-z√±\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    toks = [w for w in t.split() if (len(w) > 2 and w not in stop_words)]\n",
        "    return \" \".join(toks)\n",
        "\n",
        "def term_allowed_for_tfidf(term: str) -> bool:\n",
        "    parts = term.split()\n",
        "    return not any(p in TFIDF_CHI2_BANNED for p in parts)\n",
        "\n",
        "# ---------------------------\n",
        "# 6) CARGA DATASET\n",
        "# ---------------------------\n",
        "print(\"üì• Leyendo CSV desde GitHub RAW ...\")\n",
        "df = pd.read_csv(GITHUB_RAW_URL)\n",
        "\n",
        "assert TEXT_COL in df.columns, f\"Falta columna: {TEXT_COL}\"\n",
        "assert LABEL_COL in df.columns, f\"Falta columna: {LABEL_COL}\"\n",
        "\n",
        "df = df[[TEXT_COL, LABEL_COL]].copy()\n",
        "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str).str.strip()\n",
        "df = df[df[TEXT_COL].str.len() > 0]\n",
        "\n",
        "df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors=\"coerce\")\n",
        "df = df.dropna(subset=[LABEL_COL])\n",
        "df[LABEL_COL] = df[LABEL_COL].astype(int)\n",
        "df = df[df[LABEL_COL].isin(VALID_LABELS)].reset_index(drop=True)\n",
        "\n",
        "# Dedup por texto crudo\n",
        "df = df.drop_duplicates(subset=[TEXT_COL]).reset_index(drop=True)\n",
        "\n",
        "print(\"üßπ Creando columnas...\")\n",
        "df[\"text_tr\"] = df[TEXT_COL].apply(lambda x: normalize_for_transformer(x, remove_tilde=False))\n",
        "df[\"text_tr_noacc\"] = df[TEXT_COL].apply(lambda x: normalize_for_transformer(x, remove_tilde=True))\n",
        "df[\"text_eda\"] = df[TEXT_COL].apply(eda_aggressive)\n",
        "\n",
        "df[\"label_name\"] = df[LABEL_COL].map(LABEL_NAME)\n",
        "\n",
        "print(\"‚úÖ Shape final:\", df.shape)\n",
        "print(\"Distribuci√≥n labels (ORIGINAL):\")\n",
        "print(df[LABEL_COL].value_counts().sort_index())\n",
        "\n",
        "# HEAD para validar (raw vs train variants)\n",
        "print(\"\\nüîé EJEMPLO (raw vs text_tr vs text_tr_noacc):\")\n",
        "display(df[[TEXT_COL, \"text_tr\", \"text_tr_noacc\", LABEL_COL, \"label_name\"]].head(8))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 7) SPLITS (DESBALANCEADO)\n",
        "# ---------------------------\n",
        "def split_stratified(df_in: pd.DataFrame, label_col: str, test_size=0.15, val_size=0.15, seed=42):\n",
        "    df_train, df_temp = train_test_split(\n",
        "        df_in, test_size=(test_size + val_size),\n",
        "        stratify=df_in[label_col], random_state=seed\n",
        "    )\n",
        "    rel_test = test_size / (test_size + val_size)\n",
        "    df_val, df_test = train_test_split(\n",
        "        df_temp, test_size=rel_test,\n",
        "        stratify=df_temp[label_col], random_state=seed\n",
        "    )\n",
        "    return df_train.reset_index(drop=True), df_val.reset_index(drop=True), df_test.reset_index(drop=True)\n",
        "\n",
        "train_df, val_df, test_df = split_stratified(df, LABEL_COL, TEST_SIZE, VAL_SIZE, SEED)\n",
        "\n",
        "print(\"\\nüìå HEAD TRAIN (desbalanceado):\")\n",
        "display(train_df[[TEXT_COL, \"text_tr\", \"text_tr_noacc\", LABEL_COL, \"label_name\"]].head(8))\n",
        "\n",
        "# ---------------------------\n",
        "# 8) EDA FIGURES (distribuci√≥n + comparaci√≥n)\n",
        "# ---------------------------\n",
        "def plot_class_distribution(df_in: pd.DataFrame, title: str, fname: str):\n",
        "    counts = df_in[LABEL_COL].value_counts().sort_index()\n",
        "    labels = [LABEL_NAME[i].capitalize() for i in counts.index]\n",
        "    colors = [CLASS_COLORS.get(i, \"blue\") for i in counts.index]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(labels, counts.values, color=colors)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"N√∫mero de tuits\")\n",
        "    plt.xlabel(\"Etiqueta\")\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "plot_class_distribution(df, \"Distribuci√≥n de clases (original)\", \"01_dist_original.png\")\n",
        "\n",
        "# WordCloud por clase (usando text_eda)\n",
        "def plot_wordclouds(df_in: pd.DataFrame, text_col: str, prefix: str):\n",
        "    for lab in [0,1,2]:\n",
        "        texts = df_in[df_in[LABEL_COL]==lab][text_col].astype(str).tolist()\n",
        "        joined = \" \".join(texts).strip()\n",
        "        if not joined:\n",
        "            continue\n",
        "        wc = WordCloud(width=1200, height=600, background_color=\"white\").generate(joined)\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.imshow(wc, interpolation=\"bilinear\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"{prefix} - WordCloud ({LABEL_NAME[lab]})\")\n",
        "        save_fig(os.path.join(FIG_DIR, f\"04_{SCENARIO}_wordcloud_{lab}.png\"))\n",
        "\n",
        "plot_wordclouds(df, \"text_eda\", \"Dataset desbalanceado (EDA)\")\n",
        "\n",
        "# ---------------------------\n",
        "# 9) TF-IDF TOP + TF-IDF+chi2 TOP (filtrando marca/numero/n√∫mero/escribe)\n",
        "# ---------------------------\n",
        "def tfidf_top_by_class(df_in: pd.DataFrame, text_col=\"text_eda\", top_n=20, ngram_range=(1,2), min_df=3):\n",
        "    texts = df_in[text_col].astype(str).tolist()\n",
        "    y = df_in[LABEL_COL].astype(int).values\n",
        "\n",
        "    vec = TfidfVectorizer(lowercase=True, ngram_range=ngram_range, min_df=min_df)\n",
        "    X = vec.fit_transform(texts)\n",
        "    terms = np.array(vec.get_feature_names_out())\n",
        "\n",
        "    out = {}\n",
        "    for lab in [0,1,2]:\n",
        "        idx = np.where(y==lab)[0]\n",
        "        mean_tfidf = np.asarray(X[idx].mean(axis=0)).ravel()\n",
        "        order = np.argsort(mean_tfidf)[::-1]\n",
        "        picked = []\n",
        "        for j in order:\n",
        "            term = terms[j]\n",
        "            if term_allowed_for_tfidf(term):\n",
        "                picked.append((term, float(mean_tfidf[j])))\n",
        "            if len(picked) >= top_n:\n",
        "                break\n",
        "        out[lab] = picked\n",
        "    return out\n",
        "\n",
        "def chi2_top_by_class(df_in: pd.DataFrame, text_col=\"text_eda\", top_n=20, ngram_range=(1,2), min_df=3):\n",
        "    texts = df_in[text_col].astype(str).tolist()\n",
        "    y = df_in[LABEL_COL].astype(int).values\n",
        "\n",
        "    vec = TfidfVectorizer(lowercase=True, ngram_range=ngram_range, min_df=min_df)\n",
        "    X = vec.fit_transform(texts)\n",
        "    terms = np.array(vec.get_feature_names_out())\n",
        "\n",
        "    out = {}\n",
        "    for lab in [0,1,2]:\n",
        "        scores, _ = chi2(X, (y==lab).astype(int))\n",
        "        order = np.argsort(scores)[::-1]\n",
        "        picked = []\n",
        "        for j in order:\n",
        "            term = terms[j]\n",
        "            if term_allowed_for_tfidf(term):\n",
        "                picked.append((term, float(scores[j])))\n",
        "            if len(picked) >= top_n:\n",
        "                break\n",
        "        out[lab] = picked\n",
        "    return out\n",
        "\n",
        "def plot_kw_dict(kw_dict, title_prefix, fname_prefix, color_map=None):\n",
        "    for lab in [0,1,2]:\n",
        "        items = kw_dict.get(lab, [])\n",
        "        if not items:\n",
        "            continue\n",
        "        words = [w for w,s in items]\n",
        "        vals  = [s for w,s in items]\n",
        "        plt.figure(figsize=(7,4))\n",
        "        plt.bar(words, vals, color=CLASS_COLORS.get(lab, \"blue\"))\n",
        "        plt.title(f\"{title_prefix} ({LABEL_NAME[lab]})\")\n",
        "        plt.xticks(rotation=75, ha=\"right\")\n",
        "        save_fig(os.path.join(FIG_DIR, f\"{fname_prefix}_{lab}.png\"))\n",
        "\n",
        "kw_tfidf = tfidf_top_by_class(df, \"text_eda\", top_n=20)\n",
        "plot_kw_dict(kw_tfidf, \"TF-IDF Top 20 - desbalanceado\", \"05_desbalanceado_tfidf_top20\")\n",
        "\n",
        "kw_chi2 = chi2_top_by_class(df, \"text_eda\", top_n=20)\n",
        "plot_kw_dict(kw_chi2, \"TF-IDF + œá¬≤ Top 20 - desbalanceado\", \"06_desbalanceado_chi2_top20\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 10) HF DATASETS (solo columnas necesarias -> menos RAM)\n",
        "# ---------------------------\n",
        "def to_hf_dataset(df_train, df_val, df_test):\n",
        "    keep_cols = [LABEL_COL] + TEXT_VARIANTS_FOR_TRAIN\n",
        "    return DatasetDict(\n",
        "        train=Dataset.from_pandas(df_train[keep_cols].reset_index(drop=True)),\n",
        "        validation=Dataset.from_pandas(df_val[keep_cols].reset_index(drop=True)),\n",
        "        test=Dataset.from_pandas(df_test[keep_cols].reset_index(drop=True)),\n",
        "    )\n",
        "\n",
        "ds = to_hf_dataset(train_df, val_df, test_df)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 11) M√âTRICAS\n",
        "# ---------------------------\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"precision_macro\": precision_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
        "        \"recall_macro\": recall_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 12) PLOTS: CM azul con n√∫meros legibles + ROC multiclass\n",
        "# ---------------------------\n",
        "def plot_confusion_matrix_blue(cm, title, fname):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(3)\n",
        "    plt.xticks(tick_marks, [LABEL_NAME[i] for i in [0,1,2]])\n",
        "    plt.yticks(tick_marks, [LABEL_NAME[i] for i in [0,1,2]])\n",
        "    thresh = cm.max()/2.0 if cm.max()>0 else 0.5\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            plt.text(j, i, int(cm[i,j]),\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if cm[i,j] > thresh else \"black\",\n",
        "                     fontsize=12, fontweight=\"bold\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.xlabel(\"Predicci√≥n\")\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "def plot_multiclass_roc(y_true, y_proba, title, fname):\n",
        "    classes = [0,1,2]\n",
        "    y_bin = label_binarize(y_true, classes=classes)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, lab in enumerate(classes):\n",
        "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{LABEL_NAME[lab]} (AUC={roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_bin.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", label=f\"micro-avg (AUC={auc_micro:.3f})\")\n",
        "    plt.plot([0,1],[0,1], linestyle=\":\", linewidth=1)\n",
        "    plt.xlim([0.0,1.0]); plt.ylim([0.0,1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 13) CARGA SEGURA (ALBETO use_fast=False preferido)\n",
        "# ---------------------------\n",
        "def load_tokenizer_and_model(model_key: str, model_ckpt: str):\n",
        "    is_albert = \"albert\" in model_ckpt.lower()\n",
        "    preferred_fast = (not is_albert)\n",
        "    last_err = None\n",
        "    for use_fast in [preferred_fast, (not preferred_fast)]:\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=use_fast)\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                model_ckpt,\n",
        "                num_labels=3,\n",
        "                id2label={i: LABEL_NAME[i] for i in [0,1,2]},\n",
        "                label2id={LABEL_NAME[i]: i for i in [0,1,2]},\n",
        "            )\n",
        "            return tokenizer, model, use_fast, \"OK\"\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    return None, None, None, f\"FAIL: {last_err}\"\n",
        "\n",
        "def tokenize_dataset(ds: DatasetDict, tokenizer, text_col: str):\n",
        "    def tok(batch):\n",
        "        return tokenizer(batch[text_col], truncation=True, max_length=MAX_LEN)\n",
        "    return ds.map(tok, batched=True)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 14) TRAIN / EVAL\n",
        "# ---------------------------\n",
        "def train_and_eval(model_name_key: str, model_ckpt: str, ds: DatasetDict, text_for_model: str):\n",
        "    clear_gpu()\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"Modelo: {model_name_key} | Escenario: {SCENARIO} | Texto: {text_for_model}\")\n",
        "    print(f\"Checkpoint: {model_ckpt}\")\n",
        "    print(f\"BATCH_SIZE={BATCH_SIZE} | GRAD_ACC={GRAD_ACC} | fp16={USE_FP16}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    tokenizer, model, used_fast, status = load_tokenizer_and_model(model_name_key, model_ckpt)\n",
        "    if tokenizer is None:\n",
        "        print(\"‚ùå No se pudo cargar:\", status)\n",
        "        return {\n",
        "            \"scenario\": SCENARIO, \"text_for_model\": text_for_model, \"model\": model_name_key,\n",
        "            \"accuracy\": np.nan, \"f1_macro\": np.nan, \"precision_macro\": np.nan, \"recall_macro\": np.nan,\n",
        "            \"auc_macro_ovr\": np.nan, \"tokenizer_use_fast\": None, \"status\": status\n",
        "        }\n",
        "\n",
        "    ds_tok = tokenize_dataset(ds, tokenizer, text_for_model)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    run_dir = os.path.join(REP_DIR, f\"{SCENARIO}_{text_for_model}_{model_name_key}\".replace(\" \",\"_\"))\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=run_dir,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,                 # recomendado (ver explicaci√≥n)\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        learning_rate=LR,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRAD_ACC,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        seed=SEED,\n",
        "        fp16=USE_FP16,\n",
        "        remove_unused_columns=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=ds_tok[\"train\"],\n",
        "        eval_dataset=ds_tok[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    test_metrics = trainer.evaluate(ds_tok[\"test\"])\n",
        "    preds_out = trainer.predict(ds_tok[\"test\"])\n",
        "\n",
        "    y_true = preds_out.label_ids\n",
        "    y_pred = np.argmax(preds_out.predictions, axis=-1)\n",
        "\n",
        "    # report\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[LABEL_NAME[i] for i in [0,1,2]],\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(run_dir, \"test_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(test_metrics, f, ensure_ascii=False, indent=2)\n",
        "    with open(os.path.join(run_dir, \"classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    # Confusion matrix (azul y legible)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    cm_fname = f\"cm_{SCENARIO}_{text_for_model}_{model_name_key}.png\".replace(\" \",\"_\")\n",
        "    plot_confusion_matrix_blue(cm, f\"Matriz de confusi√≥n - {model_name_key} ({SCENARIO}) [{text_for_model}]\", cm_fname)\n",
        "\n",
        "    # ROC\n",
        "    logits = preds_out.predictions\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    roc_fname = f\"roc_{SCENARIO}_{text_for_model}_{model_name_key}.png\".replace(\" \",\"_\")\n",
        "    plot_multiclass_roc(y_true, probs, f\"ROC - {model_name_key} ({SCENARIO}) [{text_for_model}]\", roc_fname)\n",
        "\n",
        "    try:\n",
        "        y_bin = label_binarize(y_true, classes=[0,1,2])\n",
        "        auc_macro = roc_auc_score(y_bin, probs, average=\"macro\", multi_class=\"ovr\")\n",
        "    except Exception:\n",
        "        auc_macro = np.nan\n",
        "\n",
        "    return {\n",
        "        \"scenario\": SCENARIO,\n",
        "        \"text_for_model\": text_for_model,\n",
        "        \"model\": model_name_key,\n",
        "        \"accuracy\": float(test_metrics.get(\"eval_accuracy\", np.nan)),\n",
        "        \"f1_macro\": float(test_metrics.get(\"eval_f1_macro\", np.nan)),\n",
        "        \"precision_macro\": float(test_metrics.get(\"eval_precision_macro\", np.nan)),\n",
        "        \"recall_macro\": float(test_metrics.get(\"eval_recall_macro\", np.nan)),\n",
        "        \"auc_macro_ovr\": float(auc_macro),\n",
        "        \"tokenizer_use_fast\": bool(used_fast),\n",
        "        \"status\": \"OK\"\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 15) RUN EXPERIMENTS\n",
        "# ---------------------------\n",
        "results = []\n",
        "for model_name_key, ckpt in MODELS.items():\n",
        "    for text_for_model in TEXT_VARIANTS_FOR_TRAIN:\n",
        "        results.append(train_and_eval(model_name_key, ckpt, ds, text_for_model))\n",
        "\n",
        "res_df = pd.DataFrame(results).sort_values([\"text_for_model\",\"f1_macro\"], ascending=[True, False]).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"RESULTADOS FINALES (DESBALANCEADO):\")\n",
        "print(res_df[[\"scenario\",\"text_for_model\",\"model\",\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\",\"auc_macro_ovr\",\"status\"]])\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "csv_path = os.path.join(OUTPUT_DIR, \"resultados_desbalanceado.csv\")\n",
        "md_path  = os.path.join(OUTPUT_DIR, \"resultados_desbalanceado.md\")\n",
        "res_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "try:\n",
        "    md = res_df[[\"scenario\",\"text_for_model\",\"model\",\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\",\"auc_macro_ovr\",\"status\"]].to_markdown(index=False)\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(md)\n",
        "    print(\"\\nTabla Markdown (guardada):\", md_path)\n",
        "except Exception as e:\n",
        "    print(\"No se pudo generar MD:\", e)\n",
        "\n",
        "print(\"‚úÖ CSV guardado:\", csv_path)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 16) ZIP (solo artefactos TFM, NO pesos)\n",
        "# ---------------------------\n",
        "zip_path = os.path.join(\"/content\", ZIP_NAME)\n",
        "\n",
        "INCLUDE_EXT = {\".png\", \".csv\", \".md\", \".txt\", \".json\"}\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files in os.walk(OUTPUT_DIR):\n",
        "        for f in files:\n",
        "            ext = os.path.splitext(f)[1].lower()\n",
        "            if ext in INCLUDE_EXT:\n",
        "                full = os.path.join(root, f)\n",
        "                rel  = os.path.relpath(full, OUTPUT_DIR)\n",
        "                z.write(full, arcname=os.path.join(os.path.basename(OUTPUT_DIR), rel))\n",
        "\n",
        "print(\"\\n‚úÖ ZIP generado:\", zip_path)\n",
        "print(\"   En Colab: Files -> /content ->\", ZIP_NAME)\n",
        "print(\"‚úÖ Figuras:\", FIG_DIR)\n",
        "print(\"‚úÖ Reportes:\", REP_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ C√ìDIGO 2 (COLAB) ‚Äî BALANCEADO\n",
        "\n",
        "Es el mismo, pero aqu√≠ se hace undersampling antes del split."
      ],
      "metadata": {
        "id": "o9dRo1QQrx-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TFM - NLP Sentimiento Pol√≠tico (Transformers ligeros)\n",
        "# NOTEBOOK 2/2: BALANCEADO\n",
        "# Google Colab - transformers==4.44.2\n",
        "#\n",
        "# (Mismas reglas que el desbalanceado)\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install -U \"transformers==4.44.2\" datasets evaluate accelerate scikit-learn wordcloud ftfy\n",
        "\n",
        "import os, re, json, gc, random, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from ftfy import fix_text\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
        "    set_seed, EarlyStoppingCallback\n",
        ")\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1) CONFIG\n",
        "# ---------------------------\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/danielalva2008/TFM/master/TFM_UNIR/DATASETS/2.-Dataset%20Trabajados/data_extended.csv\"\n",
        "\n",
        "SCENARIO = \"balanceado\"\n",
        "ZIP_NAME = \"TFM_Balanceado_outputs.zip\"\n",
        "\n",
        "OUTPUT_DIR = \"/content/outputs_balanceado\"\n",
        "FIG_DIR    = os.path.join(OUTPUT_DIR, \"figures\")\n",
        "REP_DIR    = os.path.join(OUTPUT_DIR, \"reports\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "os.makedirs(REP_DIR, exist_ok=True)\n",
        "\n",
        "MODELS = {\n",
        "    \"DistilBERT-es\": \"dccuchile/distilbert-base-spanish-uncased\",\n",
        "    \"ALBETO Tiny\": \"dccuchile/albert-tiny-spanish\",\n",
        "    \"MiniLM Multilingual\": \"microsoft/Multilingual-MiniLM-L12-H384\",\n",
        "}\n",
        "\n",
        "TEXT_COL  = \"full_text\"\n",
        "LABEL_COL = \"label\"\n",
        "LABEL_NAME = {0: \"negativo\", 1: \"neutro\", 2: \"positivo\"}\n",
        "VALID_LABELS = set(LABEL_NAME.keys())\n",
        "\n",
        "CLASS_COLORS = {0: \"red\", 1: \"gray\", 2: \"green\"}\n",
        "\n",
        "MAX_LEN = 128\n",
        "TEST_SIZE = 0.15\n",
        "VAL_SIZE  = 0.15\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "GRAD_ACC = 1\n",
        "#TARGET_EFFECTIVE_BATCH = 32\n",
        "#GRAD_ACC = max(1, TARGET_EFFECTIVE_BATCH // BATCH_SIZE)\n",
        "\n",
        "EPOCHS = 4\n",
        "LR = 2e-5\n",
        "USE_FP16 = torch.cuda.is_available()\n",
        "EARLY_STOPPING_PATIENCE = 2\n",
        "\n",
        "TEXT_VARIANTS_FOR_TRAIN = [\"text_tr\", \"text_tr_noacc\"]\n",
        "\n",
        "TFIDF_CHI2_BANNED = {\"marca\", \"numero\", \"n√∫mero\", \"escribe\"}\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2) HELPERS\n",
        "# ---------------------------\n",
        "def clear_gpu():\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def save_fig(path):\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def fix_text_utf8(s: str) -> str:\n",
        "    return fix_text(str(s))\n",
        "\n",
        "def remove_accents(text: str) -> str:\n",
        "    pairs = [('√°','a'), ('√©','e'), ('√≠','i'), ('√≥','o'), ('√∫','u'), ('√º','u')]\n",
        "    t = str(text)\n",
        "    for a, b in pairs:\n",
        "        t = t.replace(a, b).replace(a.upper(), b.upper())\n",
        "    return t\n",
        "\n",
        "SLANG = [\n",
        "    (r\"\\bmrd\\b\", \"mierda\"),\n",
        "    (r\"\\bd\\b\", \"de\"),\n",
        "    (r\"\\b[qk]\\b\", \"que\"),\n",
        "    (r\"\\bxo\\b\", \"pero\"),\n",
        "    (r\"\\bxa\\b\", \"para\"),\n",
        "    (r\"\\b[xp]q\\b\", \"porque\"),\n",
        "    (r\"\\bes[qk]\\b\", \"es que\"),\n",
        "    (r\"\\bfvr\\b\", \"favor\"),\n",
        "    (r\"\\b(xfa|xf|pf|plis|pls|porfa)\\b\", \"por favor\"),\n",
        "    (r\"\\bdnd\\b\", \"donde\"),\n",
        "    (r\"\\btb\\b\", \"tambi√©n\"),\n",
        "    (r\"\\b(tq|tk)\\b\", \"te quiero\"),\n",
        "    (r\"\\b(tqm|tkm)\\b\", \"te quiero mucho\"),\n",
        "    (r\"\\bx\\b\", \"por\"),\n",
        "    (r\"\\+\", \"mas\"),\n",
        "    (r\"\\bpi√±a\\b\", \"mala suerte\"),\n",
        "    (r\"\\bagarre\\b\", \"adulterio\"),\n",
        "    (r\"\\bampay\\b\", \"verguenza\"),\n",
        "    (r\"\\bbacan\\b\", \"alegria\"),\n",
        "    (r\"\\bbamba\\b\", \"falsificado\"),\n",
        "    (r\"\\bcabeceador\\b\", \"ladron\"),\n",
        "    (r\"\\bcabro\\b\", \"homosexual\"),\n",
        "    (r\"\\bcachaciento\\b\", \"burlon\"),\n",
        "    (r\"\\bcalabacita\\b\", \"tonta\"),\n",
        "    (r\"\\bcaleta\\b\", \"secreto\"),\n",
        "    (r\"\\bcana\\b\", \"carcel\"),\n",
        "    (r\"\\bchucha\\b\", \"molestia\"),\n",
        "    (r\"\\bchoro\\b\", \"ladron\"),\n",
        "    (r\"\\bconch√°n\\b\", \"conchudo\"),\n",
        "    (r\"\\bcutra\\b\", \"ilicito\"),\n",
        "    (r\"\\bdark\\b\", \"horrible\"),\n",
        "    (r\"\\blenteja\\b\", \"torpe\"),\n",
        "    (r\"\\blorna\\b\", \"tonto\"),\n",
        "    (r\"\\bmancar\\b\", \"morir\"),\n",
        "    (r\"\\bmonse\\b\", \"tonto\"),\n",
        "    (r\"\\bpi√±ata\\b\", \"mala suerte\"),\n",
        "]\n",
        "\n",
        "def apply_slang(t: str) -> str:\n",
        "    for pat, rep in SLANG:\n",
        "        t = re.sub(pat, rep, t)\n",
        "    return t\n",
        "\n",
        "stop_words = set([\n",
        "    'a', 'adelante', 'adem√°s', 'afirm√≥', 'agreg√≥', 'ahi', 'ahora', 'ah√≠', 'al',\n",
        "    'algo', 'alguna', 'algunas', 'alguno', 'algunos', 'alg√∫n', 'alrededor', 'ambos',\n",
        "    'ampleamos', 'ante', 'anterior', 'antes', 'apenas', 'aproximadamente', 'aquel',\n",
        "    'aquellas', 'aquellos', 'aqui', 'aqu√≠', 'arriba', 'as', 'asegur√≥', 'asi', 'as√≠',\n",
        "    'atras', 'aunque', 'a√∫n', 'ayer', 'b', 'bajo', 'bastante', 'bien', 'buen',\n",
        "    'buena', 'buenas', 'bueno', 'buenos', 'c', 'cada', 'casi', 'cc', 'cerca',\n",
        "    'cierta', 'ciertas', 'cierto', 'ciertos', 'cinco', 'coment√≥', 'como', 'con',\n",
        "    'conocer', 'conseguimos', 'conseguir', 'considera', 'consider√≥', 'consigue',\n",
        "    'consiguen', 'consigues', 'consigo', 'contra', 'cosas', 'creo', 'cual',\n",
        "    'cuales', 'cualquier', 'cuando', 'cuanto', 'cuatro', 'cuenta', 'c√≥mo', 'd',\n",
        "    'da', 'dado', 'dan', 'dar', 'de', 'debe', 'deben', 'debido', 'decir', 'dej√≥',\n",
        "    'del', 'dem√°s', 'dentro', 'desde', 'despu√©s', 'dia', 'dice', 'dicen', 'dicho',\n",
        "    'dieron', 'diferente', 'diferentes', 'dijeron', 'dijo', 'dio', 'do', 'don',\n",
        "    'donde', 'dos', 'durante', 'e', 'ejemplo', 'el', 'ella', 'ellas', 'ello',\n",
        "    'ellos', 'embargo', 'empleais', 'emplean', 'emplear', 'empleas', 'empleo',\n",
        "    'en', 'encima', 'encuentra', 'entonces', 'entre', 'era', 'eramos', 'eran',\n",
        "    'eras', 'eres', 'es', 'esa', 'esas', 'ese', 'eso', 'esos', 'esta', 'estaba',\n",
        "    'estaban', 'estado', 'estais', 'estamos', 'estan', 'estar', 'estar√°', 'estas',\n",
        "    'este', 'esto', 'estos', 'estoy', 'estuvo', 'ex', 'existe', 'existen',\n",
        "    'explic√≥', 'expres√≥', 'f', 'fin', 'fue', 'fuera', 'fueron', 'fui', 'fuimos',\n",
        "    'g', 'gran', 'grandes', 'gueno', 'h', 'ha', 'haber', 'hab√≠a', 'hab√≠an',\n",
        "    'habr√°', 'hace', 'haceis', 'hacemos', 'hacen', 'hacer', 'hacerlo', 'haces',\n",
        "    'hacia', 'haciendo', 'hago', 'han', 'has', 'hasta', 'hay', 'haya', 'he',\n",
        "    'hecho', 'hemos', 'hicieron', 'hizo', 'hoy', 'hubo', 'i', 'igual', 'incluso',\n",
        "    'indic√≥', 'inform√≥', 'intenta', 'intentais', 'intentamos', 'intentan',\n",
        "    'intentar', 'intentas', 'intento', 'ir', 'is', 'j', 'junto', 'k', 'l', 'la',\n",
        "    'lado', 'largo', 'las', 'le', 'les', 'lleg√≥', 'lleva', 'llevar', 'lo', 'los',\n",
        "    'luego', 'lugar', 'm', 'manera', 'manifest√≥', 'mas', 'mayor', 'me', 'mediante',\n",
        "    'mejor', 'mencion√≥', 'menos', 'mi', 'mientras', 'mio', 'mis', 'misma',\n",
        "    'mismas', 'mismo', 'mismos', 'mo', 'modo', 'momento', 'mucha', 'muchas',\n",
        "    'mucho', 'muchos', 'muy', 'm√°s', 'n', 'nada', 'nadie', 'ni', 'ninguna',\n",
        "    'ningunas', 'ninguno', 'ningunos', 'ning√∫n', 'nos', 'nosotras', 'nosotros',\n",
        "    'nuestra', 'nuestras', 'nuestro', 'nuestros', 'nueva', 'nuevas', 'nuevo',\n",
        "    'nuevos', 'nunca', 'o', 'ocho', 'of', 'otra', 'otras', 'otro', 'otros',\n",
        "    'p', 'pa', 'para', 'parece', 'parte', 'partir', 'pasada', 'pasado', 'pero',\n",
        "    'pesar', 'poca', 'pocas', 'poco', 'pocos', 'podeis', 'podemos', 'poder',\n",
        "    'podra', 'podr√°n', 'podria', 'podriais', 'podriamos', 'podrian', 'podrias',\n",
        "    'podr√≠a', 'podr√≠an', 'poner', 'por', 'porque', 'por qu√©', 'posible', 'pq',\n",
        "    'primer', 'primera', 'primero', 'primeros', 'principalmente', 'propia',\n",
        "    'propias', 'propio', 'propios', 'pr√≥ximo', 'pr√≥ximos', 'pt', 'pudo', 'pueda',\n",
        "    'puede', 'pueden', 'puedo', 'pues', 'q', 'qie', 'qu', 'que', 'qued√≥',\n",
        "    'queremos', 'quien', 'quienes', 'quiere', 'qu√©', 'qui√©n', 'r', 'realizado',\n",
        "    'realizar', 'realiz√≥', 'respecto', 's', 'sabe', 'sabeis', 'sabemos', 'saben',\n",
        "    'saber', 'sabes', 'se', 'sea', 'sean', 'segunda', 'segundo', 'seg√∫n', 'seis',\n",
        "    'sera', 'ser√°', 'ser√°n', 'ser√≠a', 'si', 'sido', 'siempre', 'siendo', 'siete',\n",
        "    'sigue', 'siguiente', 'sin', 'sino', 'sobre', 'sois', 'sola', 'solamente',\n",
        "    'solas', 'solo', 'solos', 'somos', 'son', 'soy', 'su', 'sua', 'sus', 's√≠',\n",
        "    's√≥lo', 'se√±al√≥', 't', 'tal', 'tambi√©n', 'tampoco', 'tan', 'tanto', 'te',\n",
        "    'tendr√°', 'tendr√°n', 'teneis', 'tenemos', 'tener', 'tenga', 'tengo', 'ten√≠a',\n",
        "    'tenido', 'tercera', 'the', 'ti', 'tiempo', 'tiene', 'tienen', 'to', 'toda',\n",
        "    'todas', 'todav√≠a', 'todo', 'todos', 'total', 'trabaja', 'trabajais',\n",
        "    'trabajamos', 'trabajan', 'trabajar', 'trabajas', 'trabajo', 'tras',\n",
        "    'trata', 'trav√©s', 'tres', 'tu', 'tus', 'tuvo', 'tuyo', 'u', 'un', 'una',\n",
        "    'unas', 'uno', 'unos', 'us', 'usa', 'usais', 'usamos', 'usan', 'usar',\n",
        "    'usas', 'uso', 'usted', 'v', 'va', 'vais', 'valor', 'vamos', 'van',\n",
        "    'varias', 'varios', 'vaya', 'veces', 'ven', 'ver', 'verdad', 'verdadera',\n",
        "    'verdadero', 'vez', 'via', 'vosotras', 'vosotros', 'voy', 'w', 'x', 'y',\n",
        "    'ya', 'yo', 'z', '√°', '√©sta', '√©ste', '√©stas', '√©stos', '√∫ltima', '√∫ltimas',\n",
        "    'ultimo', '√∫ltimo', '√∫ltimos'\n",
        "])\n",
        "\n",
        "def normalize_for_transformer(text: str, remove_tilde: bool = False) -> str:\n",
        "    t = fix_text_utf8(text).lower()\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\w+\", \" \", t)\n",
        "    t = re.sub(r\"#\\w+\", \" \", t)\n",
        "    t = apply_slang(t)\n",
        "    t = re.sub(r\"[^a-z√°√©√≠√≥√∫√±√º\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    if remove_tilde:\n",
        "        t = remove_accents(t)\n",
        "        t = re.sub(r\"[^a-z√±\\s]\", \" \", t)\n",
        "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "def eda_aggressive(text: str) -> str:\n",
        "    t = fix_text_utf8(text).lower()\n",
        "    t = apply_slang(t)\n",
        "    t = remove_accents(t)\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\w+\", \" \", t)\n",
        "    t = re.sub(r\"#\\w+\", \" \", t)\n",
        "    t = re.sub(r\"[^a-z√±\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    toks = [w for w in t.split() if (len(w) > 2 and w not in stop_words)]\n",
        "    return \" \".join(toks)\n",
        "\n",
        "def term_allowed_for_tfidf(term: str) -> bool:\n",
        "    parts = term.split()\n",
        "    return not any(p in TFIDF_CHI2_BANNED for p in parts)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 3) CARGA DATASET\n",
        "# ---------------------------\n",
        "print(\"üì• Leyendo CSV desde GitHub RAW ...\")\n",
        "df = pd.read_csv(GITHUB_RAW_URL)\n",
        "\n",
        "df = df[[TEXT_COL, LABEL_COL]].copy()\n",
        "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str).str.strip()\n",
        "df = df[df[TEXT_COL].str.len() > 0]\n",
        "\n",
        "df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors=\"coerce\")\n",
        "df = df.dropna(subset=[LABEL_COL])\n",
        "df[LABEL_COL] = df[LABEL_COL].astype(int)\n",
        "df = df[df[LABEL_COL].isin(VALID_LABELS)].reset_index(drop=True)\n",
        "\n",
        "df = df.drop_duplicates(subset=[TEXT_COL]).reset_index(drop=True)\n",
        "\n",
        "df[\"text_tr\"] = df[TEXT_COL].apply(lambda x: normalize_for_transformer(x, remove_tilde=False))\n",
        "df[\"text_tr_noacc\"] = df[TEXT_COL].apply(lambda x: normalize_for_transformer(x, remove_tilde=True))\n",
        "df[\"text_eda\"] = df[TEXT_COL].apply(eda_aggressive)\n",
        "df[\"label_name\"] = df[LABEL_COL].map(LABEL_NAME)\n",
        "\n",
        "print(\"‚úÖ Shape final:\", df.shape)\n",
        "print(\"Distribuci√≥n labels (ORIGINAL):\")\n",
        "print(df[LABEL_COL].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nüîé EJEMPLO (raw vs text_tr vs text_tr_noacc):\")\n",
        "display(df[[TEXT_COL, \"text_tr\", \"text_tr_noacc\", LABEL_COL, \"label_name\"]].head(8))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4) BALANCEO (undersampling)\n",
        "# ---------------------------\n",
        "def make_balanced_undersampling(df_in: pd.DataFrame, label_col: str, seed=42) -> pd.DataFrame:\n",
        "    counts = df_in[label_col].value_counts()\n",
        "    n_min = counts.min()\n",
        "    parts = []\n",
        "    for lab in sorted(counts.index):\n",
        "        parts.append(df_in[df_in[label_col] == lab].sample(n=n_min, random_state=seed))\n",
        "    return pd.concat(parts).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "df_bal = make_balanced_undersampling(df, LABEL_COL, seed=SEED)\n",
        "\n",
        "print(\"\\nDistribuci√≥n labels (BALANCEADO):\")\n",
        "print(df_bal[LABEL_COL].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nüìå HEAD BALANCEADO:\")\n",
        "display(df_bal[[TEXT_COL, \"text_tr\", \"text_tr_noacc\", LABEL_COL, \"label_name\"]].head(8))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) SPLITS (BALANCEADO)\n",
        "# ---------------------------\n",
        "def split_stratified(df_in: pd.DataFrame, label_col: str, test_size=0.15, val_size=0.15, seed=42):\n",
        "    df_train, df_temp = train_test_split(\n",
        "        df_in, test_size=(test_size + val_size),\n",
        "        stratify=df_in[label_col], random_state=seed\n",
        "    )\n",
        "    rel_test = test_size / (test_size + val_size)\n",
        "    df_val, df_test = train_test_split(\n",
        "        df_temp, test_size=rel_test,\n",
        "        stratify=df_temp[label_col], random_state=seed\n",
        "    )\n",
        "    return df_train.reset_index(drop=True), df_val.reset_index(drop=True), df_test.reset_index(drop=True)\n",
        "\n",
        "train_df, val_df, test_df = split_stratified(df_bal, LABEL_COL, TEST_SIZE, VAL_SIZE, SEED)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 6) EDA FIGURES (distribuci√≥n + comparaci√≥n)\n",
        "# ---------------------------\n",
        "def plot_class_distribution(df_in: pd.DataFrame, title: str, fname: str):\n",
        "    counts = df_in[LABEL_COL].value_counts().sort_index()\n",
        "    labels = [LABEL_NAME[i].capitalize() for i in counts.index]\n",
        "    colors = [CLASS_COLORS.get(i, \"blue\") for i in counts.index]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(labels, counts.values, color=colors)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"N√∫mero de tuits\")\n",
        "    plt.xlabel(\"Etiqueta\")\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "def plot_class_comparison(df_orig: pd.DataFrame, df_balanced: pd.DataFrame, title: str, fname: str):\n",
        "    idx = [0,1,2]\n",
        "    orig_counts = df_orig[LABEL_COL].value_counts().reindex(idx, fill_value=0)\n",
        "    bal_counts  = df_balanced[LABEL_COL].value_counts().reindex(idx, fill_value=0)\n",
        "    labels = [LABEL_NAME[i].capitalize() for i in idx]\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(x - width/2, orig_counts.values, width, label=\"Original\")\n",
        "    plt.bar(x + width/2, bal_counts.values,  width, label=\"Balanceado\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Etiqueta\")\n",
        "    plt.ylabel(\"N√∫mero de tuits\")\n",
        "    plt.xticks(x, labels)\n",
        "    plt.legend()\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "plot_class_distribution(df, \"Distribuci√≥n de clases (original)\", \"01_dist_original.png\")\n",
        "plot_class_distribution(df_bal, \"Distribuci√≥n de clases (balanceado)\", \"02_dist_balanceado.png\")\n",
        "plot_class_comparison(df, df_bal, \"Comparaci√≥n de distribuci√≥n de clases\", \"03_comp_dist_original_vs_balanceado.png\")\n",
        "\n",
        "def plot_wordclouds(df_in: pd.DataFrame, text_col: str, prefix: str):\n",
        "    for lab in [0,1,2]:\n",
        "        texts = df_in[df_in[LABEL_COL]==lab][text_col].astype(str).tolist()\n",
        "        joined = \" \".join(texts).strip()\n",
        "        if not joined:\n",
        "            continue\n",
        "        wc = WordCloud(width=1200, height=600, background_color=\"white\").generate(joined)\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.imshow(wc, interpolation=\"bilinear\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"{prefix} - WordCloud ({LABEL_NAME[lab]})\")\n",
        "        save_fig(os.path.join(FIG_DIR, f\"04_{SCENARIO}_wordcloud_{lab}.png\"))\n",
        "\n",
        "plot_wordclouds(df_bal, \"text_eda\", \"Dataset balanceado (EDA)\")\n",
        "\n",
        "def tfidf_top_by_class(df_in: pd.DataFrame, text_col=\"text_eda\", top_n=20, ngram_range=(1,2), min_df=3):\n",
        "    texts = df_in[text_col].astype(str).tolist()\n",
        "    y = df_in[LABEL_COL].astype(int).values\n",
        "    vec = TfidfVectorizer(lowercase=True, ngram_range=ngram_range, min_df=min_df)\n",
        "    X = vec.fit_transform(texts)\n",
        "    terms = np.array(vec.get_feature_names_out())\n",
        "    out = {}\n",
        "    for lab in [0,1,2]:\n",
        "        idx = np.where(y==lab)[0]\n",
        "        mean_tfidf = np.asarray(X[idx].mean(axis=0)).ravel()\n",
        "        order = np.argsort(mean_tfidf)[::-1]\n",
        "        picked = []\n",
        "        for j in order:\n",
        "            term = terms[j]\n",
        "            if term_allowed_for_tfidf(term):\n",
        "                picked.append((term, float(mean_tfidf[j])))\n",
        "            if len(picked) >= top_n:\n",
        "                break\n",
        "        out[lab] = picked\n",
        "    return out\n",
        "\n",
        "def chi2_top_by_class(df_in: pd.DataFrame, text_col=\"text_eda\", top_n=20, ngram_range=(1,2), min_df=3):\n",
        "    texts = df_in[text_col].astype(str).tolist()\n",
        "    y = df_in[LABEL_COL].astype(int).values\n",
        "    vec = TfidfVectorizer(lowercase=True, ngram_range=ngram_range, min_df=min_df)\n",
        "    X = vec.fit_transform(texts)\n",
        "    terms = np.array(vec.get_feature_names_out())\n",
        "    out = {}\n",
        "    for lab in [0,1,2]:\n",
        "        scores, _ = chi2(X, (y==lab).astype(int))\n",
        "        order = np.argsort(scores)[::-1]\n",
        "        picked = []\n",
        "        for j in order:\n",
        "            term = terms[j]\n",
        "            if term_allowed_for_tfidf(term):\n",
        "                picked.append((term, float(scores[j])))\n",
        "            if len(picked) >= top_n:\n",
        "                break\n",
        "        out[lab] = picked\n",
        "    return out\n",
        "\n",
        "def plot_kw_dict(kw_dict, title_prefix, fname_prefix):\n",
        "    for lab in [0,1,2]:\n",
        "        items = kw_dict.get(lab, [])\n",
        "        if not items:\n",
        "            continue\n",
        "        words = [w for w,s in items]\n",
        "        vals  = [s for w,s in items]\n",
        "        plt.figure(figsize=(7,4))\n",
        "        plt.bar(words, vals, color=CLASS_COLORS.get(lab, \"blue\"))\n",
        "        plt.title(f\"{title_prefix} ({LABEL_NAME[lab]})\")\n",
        "        plt.xticks(rotation=75, ha=\"right\")\n",
        "        save_fig(os.path.join(FIG_DIR, f\"{fname_prefix}_{lab}.png\"))\n",
        "\n",
        "kw_tfidf = tfidf_top_by_class(df_bal, \"text_eda\", top_n=20)\n",
        "plot_kw_dict(kw_tfidf, \"TF-IDF Top 20 - balanceado\", \"05_balanceado_tfidf_top20\")\n",
        "kw_chi2 = chi2_top_by_class(df_bal, \"text_eda\", top_n=20)\n",
        "plot_kw_dict(kw_chi2, \"TF-IDF + œá¬≤ Top 20 - balanceado\", \"06_balanceado_chi2_top20\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 7) HF DATASETS (solo columnas necesarias)\n",
        "# ---------------------------\n",
        "def to_hf_dataset(df_train, df_val, df_test):\n",
        "    keep_cols = [LABEL_COL] + TEXT_VARIANTS_FOR_TRAIN\n",
        "    return DatasetDict(\n",
        "        train=Dataset.from_pandas(df_train[keep_cols].reset_index(drop=True)),\n",
        "        validation=Dataset.from_pandas(df_val[keep_cols].reset_index(drop=True)),\n",
        "        test=Dataset.from_pandas(df_test[keep_cols].reset_index(drop=True)),\n",
        "    )\n",
        "\n",
        "ds = to_hf_dataset(train_df, val_df, test_df)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 8) M√âTRICAS\n",
        "# ---------------------------\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"precision_macro\": precision_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
        "        \"recall_macro\": recall_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 9) CM + ROC\n",
        "# ---------------------------\n",
        "def plot_confusion_matrix_blue(cm, title, fname):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(3)\n",
        "    plt.xticks(tick_marks, [LABEL_NAME[i] for i in [0,1,2]])\n",
        "    plt.yticks(tick_marks, [LABEL_NAME[i] for i in [0,1,2]])\n",
        "    thresh = cm.max()/2.0 if cm.max()>0 else 0.5\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            plt.text(j, i, int(cm[i,j]),\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if cm[i,j] > thresh else \"black\",\n",
        "                     fontsize=12, fontweight=\"bold\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.xlabel(\"Predicci√≥n\")\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "def plot_multiclass_roc(y_true, y_proba, title, fname):\n",
        "    classes = [0,1,2]\n",
        "    y_bin = label_binarize(y_true, classes=classes)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, lab in enumerate(classes):\n",
        "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{LABEL_NAME[lab]} (AUC={roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_bin.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", label=f\"micro-avg (AUC={auc_micro:.3f})\")\n",
        "    plt.plot([0,1],[0,1], linestyle=\":\", linewidth=1)\n",
        "    plt.xlim([0.0,1.0]); plt.ylim([0.0,1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    save_fig(os.path.join(FIG_DIR, fname))\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 10) LOAD + TOKENIZE (ALBETO safe)\n",
        "# ---------------------------\n",
        "def load_tokenizer_and_model(model_key: str, model_ckpt: str):\n",
        "    is_albert = \"albert\" in model_ckpt.lower()\n",
        "    preferred_fast = (not is_albert)\n",
        "    last_err = None\n",
        "    for use_fast in [preferred_fast, (not preferred_fast)]:\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=use_fast)\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                model_ckpt,\n",
        "                num_labels=3,\n",
        "                id2label={i: LABEL_NAME[i] for i in [0,1,2]},\n",
        "                label2id={LABEL_NAME[i]: i for i in [0,1,2]},\n",
        "            )\n",
        "            return tokenizer, model, use_fast, \"OK\"\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    return None, None, None, f\"FAIL: {last_err}\"\n",
        "\n",
        "def tokenize_dataset(ds: DatasetDict, tokenizer, text_col: str):\n",
        "    def tok(batch):\n",
        "        return tokenizer(batch[text_col], truncation=True, max_length=MAX_LEN)\n",
        "    return ds.map(tok, batched=True)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 11) TRAIN / EVAL\n",
        "# ---------------------------\n",
        "def train_and_eval(model_name_key: str, model_ckpt: str, ds: DatasetDict, text_for_model: str):\n",
        "    clear_gpu()\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"Modelo: {model_name_key} | Escenario: {SCENARIO} | Texto: {text_for_model}\")\n",
        "    print(f\"BATCH_SIZE={BATCH_SIZE} | GRAD_ACC={GRAD_ACC} | fp16={USE_FP16}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    tokenizer, model, used_fast, status = load_tokenizer_and_model(model_name_key, model_ckpt)\n",
        "    if tokenizer is None:\n",
        "        print(\"‚ùå No se pudo cargar:\", status)\n",
        "        return {\n",
        "            \"scenario\": SCENARIO, \"text_for_model\": text_for_model, \"model\": model_name_key,\n",
        "            \"accuracy\": np.nan, \"f1_macro\": np.nan, \"precision_macro\": np.nan, \"recall_macro\": np.nan,\n",
        "            \"auc_macro_ovr\": np.nan, \"tokenizer_use_fast\": None, \"status\": status\n",
        "        }\n",
        "\n",
        "    ds_tok = tokenize_dataset(ds, tokenizer, text_for_model)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    run_dir = os.path.join(REP_DIR, f\"{SCENARIO}_{text_for_model}_{model_name_key}\".replace(\" \",\"_\"))\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=run_dir,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        learning_rate=LR,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRAD_ACC,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        seed=SEED,\n",
        "        fp16=USE_FP16,\n",
        "        remove_unused_columns=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=ds_tok[\"train\"],\n",
        "        eval_dataset=ds_tok[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    test_metrics = trainer.evaluate(ds_tok[\"test\"])\n",
        "    preds_out = trainer.predict(ds_tok[\"test\"])\n",
        "\n",
        "    y_true = preds_out.label_ids\n",
        "    y_pred = np.argmax(preds_out.predictions, axis=-1)\n",
        "\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[LABEL_NAME[i] for i in [0,1,2]],\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    with open(os.path.join(run_dir, \"test_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(test_metrics, f, ensure_ascii=False, indent=2)\n",
        "    with open(os.path.join(run_dir, \"classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    cm_fname = f\"cm_{SCENARIO}_{text_for_model}_{model_name_key}.png\".replace(\" \",\"_\")\n",
        "    plot_confusion_matrix_blue(cm, f\"Matriz de confusi√≥n - {model_name_key} ({SCENARIO}) [{text_for_model}]\", cm_fname)\n",
        "\n",
        "    logits = preds_out.predictions\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    roc_fname = f\"roc_{SCENARIO}_{text_for_model}_{model_name_key}.png\".replace(\" \",\"_\")\n",
        "    plot_multiclass_roc(y_true, probs, f\"ROC - {model_name_key} ({SCENARIO}) [{text_for_model}]\", roc_fname)\n",
        "\n",
        "    try:\n",
        "        y_bin = label_binarize(y_true, classes=[0,1,2])\n",
        "        auc_macro = roc_auc_score(y_bin, probs, average=\"macro\", multi_class=\"ovr\")\n",
        "    except Exception:\n",
        "        auc_macro = np.nan\n",
        "\n",
        "    return {\n",
        "        \"scenario\": SCENARIO,\n",
        "        \"text_for_model\": text_for_model,\n",
        "        \"model\": model_name_key,\n",
        "        \"accuracy\": float(test_metrics.get(\"eval_accuracy\", np.nan)),\n",
        "        \"f1_macro\": float(test_metrics.get(\"eval_f1_macro\", np.nan)),\n",
        "        \"precision_macro\": float(test_metrics.get(\"eval_precision_macro\", np.nan)),\n",
        "        \"recall_macro\": float(test_metrics.get(\"eval_recall_macro\", np.nan)),\n",
        "        \"auc_macro_ovr\": float(auc_macro),\n",
        "        \"tokenizer_use_fast\": bool(used_fast),\n",
        "        \"status\": \"OK\"\n",
        "    }\n",
        "\n",
        "results = []\n",
        "for model_name_key, ckpt in MODELS.items():\n",
        "    for text_for_model in TEXT_VARIANTS_FOR_TRAIN:\n",
        "        results.append(train_and_eval(model_name_key, ckpt, ds, text_for_model))\n",
        "\n",
        "res_df = pd.DataFrame(results).sort_values([\"text_for_model\",\"f1_macro\"], ascending=[True, False]).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"RESULTADOS FINALES (BALANCEADO):\")\n",
        "print(res_df[[\"scenario\",\"text_for_model\",\"model\",\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\",\"auc_macro_ovr\",\"status\"]])\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "csv_path = os.path.join(OUTPUT_DIR, \"resultados_balanceado.csv\")\n",
        "md_path  = os.path.join(OUTPUT_DIR, \"resultados_balanceado.md\")\n",
        "res_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "try:\n",
        "    md = res_df[[\"scenario\",\"text_for_model\",\"model\",\"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\",\"auc_macro_ovr\",\"status\"]].to_markdown(index=False)\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(md)\n",
        "    print(\"\\nTabla Markdown (guardada):\", md_path)\n",
        "except Exception as e:\n",
        "    print(\"No se pudo generar MD:\", e)\n",
        "\n",
        "print(\"‚úÖ CSV guardado:\", csv_path)\n",
        "\n",
        "zip_path = os.path.join(\"/content\", ZIP_NAME)\n",
        "INCLUDE_EXT = {\".png\", \".csv\", \".md\", \".txt\", \".json\"}\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files in os.walk(OUTPUT_DIR):\n",
        "        for f in files:\n",
        "            ext = os.path.splitext(f)[1].lower()\n",
        "            if ext in INCLUDE_EXT:\n",
        "                full = os.path.join(root, f)\n",
        "                rel  = os.path.relpath(full, OUTPUT_DIR)\n",
        "                z.write(full, arcname=os.path.join(os.path.basename(OUTPUT_DIR), rel))\n",
        "\n",
        "print(\"\\n‚úÖ ZIP generado:\", zip_path)\n",
        "print(\"   En Colab: Files -> /content ->\", ZIP_NAME)\n",
        "print(\"‚úÖ Figuras:\", FIG_DIR)\n",
        "print(\"‚úÖ Reportes:\", REP_DIR)\n"
      ],
      "metadata": {
        "id": "kFAt0sJQr1x3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHxSIJePqCaOHUkVlFmc/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjl-ai/TFM-Sentimiento-Politico-Transformers/blob/main/notebooks%20/TransformerLigeros_caso_balanceado_y_desbalanceado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#âœ… TRANSFORMES LIGEROS ESCENARIO DATASET: BALANCEADO Y DESBALANCEADO\n",
        "\n"
      ],
      "metadata": {
        "id": "ZmBFCOsrrMR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TFM - NLP Sentimiento PolÃ­tico (Transformers ligeros)\n",
        "# NOTEBOOK ÃšNICO (COPIAR/PEGAR) - Ajustado a:\n",
        "# âœ… EarlyStopping + load_best_model_at_end (como antes)\n",
        "# âœ… Checkpoints SÃ se generan para entrenar, PERO:\n",
        "#    - NO se incluyen en el ZIP\n",
        "#    - se guardan fuera de la carpeta del ZIP y se BORRAN al final de cada run\n",
        "# âœ… TOP 20 palabras GENERAL (EDA normalizado: text_eda) para:\n",
        "#    - escenario desbalanceado\n",
        "#    - escenario balanceado\n",
        "# âœ… ZIP SOLO con TABLAS y FIGURAS (NO checkpoints)\n",
        "# âœ… Indica cuÃ¡ntos registros se usan en entrenamiento (train split) por escenario\n",
        "# âœ… + NUEVO: 3 grÃ¡ficos de distribuciÃ³n de clases:\n",
        "#    1) balanceado, 2) desbalanceado, 3) comparativo\n",
        "# âœ… + NUEVO: tabla comparativa incluye mÃ©tricas de LOSS\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install -U \"transformers==4.44.2\" datasets evaluate accelerate scikit-learn wordcloud ftfy\n",
        "\n",
        "import os, re, gc, random, zipfile, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from ftfy import fix_text\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
        "    set_seed, EarlyStoppingCallback\n",
        ")\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# ---------------------------\n",
        "# 1) CONFIG\n",
        "# ---------------------------\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# âœ… Usar CSV subido (si existe) y fallback a GitHub\n",
        "LOCAL_CSV = \"/mnt/data/data_extended (1).csv\"\n",
        "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/danielalva2008/TFM/master/TFM_UNIR/DATASETS/2.-Dataset%20Trabajados/data_extended.csv\"\n",
        "\n",
        "# âœ… ZIP solo tablas+figuras\n",
        "ZIP_NAME = \"TFM_SOLO_TABLAS_Y_FIGURAS.zip\"\n",
        "BASE_OUTPUT_DIR = \"/content/outputs_tfm_solo_tablas_figuras\"\n",
        "\n",
        "# âœ… IMPORTANTE: carpeta Figuras/ como en tu LaTeX\n",
        "FIG_DIR = os.path.join(BASE_OUTPUT_DIR, \"Figuras\")\n",
        "TAB_DIR = os.path.join(BASE_OUTPUT_DIR, \"tables\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "os.makedirs(TAB_DIR, exist_ok=True)\n",
        "\n",
        "# âœ… Checkpoints (fuera del ZIP) -> y se borran al final de cada entrenamiento\n",
        "CKPT_ROOT = \"/content/_tfm_checkpoints_tmp\"   # NO estÃ¡ dentro de BASE_OUTPUT_DIR\n",
        "os.makedirs(CKPT_ROOT, exist_ok=True)\n",
        "\n",
        "MODELS = {\n",
        "    \"DistilBERT-es\": \"dccuchile/distilbert-base-spanish-uncased\",\n",
        "    \"ALBETO_Tiny\": \"dccuchile/albert-tiny-spanish\",\n",
        "    \"MiniLM_Multilingual\": \"microsoft/Multilingual-MiniLM-L12-H384\",\n",
        "}\n",
        "\n",
        "TEXT_COL  = \"full_text\"\n",
        "LABEL_COL = \"label\"\n",
        "LABEL_NAME = {0: \"negativo\", 1: \"neutro\", 2: \"positivo\"}\n",
        "VALID_LABELS = set(LABEL_NAME.keys())\n",
        "\n",
        "MAX_LEN = 128\n",
        "TEST_SIZE = 0.15\n",
        "VAL_SIZE  = 0.15\n",
        "\n",
        "# âœ… Batch efectivo como pediste\n",
        "BATCH_SIZE = 16\n",
        "TARGET_EFFECTIVE_BATCH = 32\n",
        "GRAD_ACC = max(1, TARGET_EFFECTIVE_BATCH // BATCH_SIZE)\n",
        "print(f\"âœ… BATCH_SIZE={BATCH_SIZE} | TARGET_EFFECTIVE_BATCH={TARGET_EFFECTIVE_BATCH} | GRAD_ACC={GRAD_ACC}\")\n",
        "\n",
        "EPOCHS = 4\n",
        "LR = 2e-5\n",
        "USE_FP16 = torch.cuda.is_available()\n",
        "EARLY_STOPPING_PATIENCE = 2\n",
        "\n",
        "# âœ… SOLO columna entrenamiento (con tildes)\n",
        "TEXT_FOR_TRAIN = \"text_tr\"\n",
        "\n",
        "# âœ… Filtro para TF-IDF/Chi2\n",
        "TFIDF_CHI2_BANNED = {\"marca\", \"numero\", \"nÃºmero\", \"escribe\"}\n",
        "\n",
        "SCENARIOS = [\n",
        "    {\"name\": \"desbalanceado\", \"balanced\": False},\n",
        "    {\"name\": \"balanceado\", \"balanced\": True},\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# 2) HELPERS\n",
        "# ---------------------------\n",
        "def clear_gpu():\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def save_fig_jpg(path_no_ext: str):\n",
        "    path = path_no_ext if path_no_ext.lower().endswith(\".jpg\") else (path_no_ext + \".jpg\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=220, bbox_inches=\"tight\", format=\"jpg\")\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def fix_text_utf8(s: str) -> str:\n",
        "    return fix_text(str(s))\n",
        "\n",
        "def remove_accents(text: str) -> str:\n",
        "    pairs = [('Ã¡','a'), ('Ã©','e'), ('Ã­','i'), ('Ã³','o'), ('Ãº','u'), ('Ã¼','u')]\n",
        "    t = str(text)\n",
        "    for a, b in pairs:\n",
        "        t = t.replace(a, b).replace(a.upper(), b.upper())\n",
        "    return t\n",
        "\n",
        "def term_allowed_for_tfidf(term: str) -> bool:\n",
        "    parts = term.split()\n",
        "    return not any(p in TFIDF_CHI2_BANNED for p in parts)\n",
        "\n",
        "def save_markdown_table(df: pd.DataFrame, md_path: str, title: str):\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"# {title}\\n\\n\")\n",
        "        f.write(df.to_markdown(index=False))\n",
        "\n",
        "# âœ… NUEVO: grÃ¡ficos de distribuciÃ³n de clases (3 grÃ¡ficos pedidos)\n",
        "def plot_class_distribution(df_in: pd.DataFrame, title: str, fname_noext: str):\n",
        "    counts = df_in[LABEL_COL].value_counts().reindex([0,1,2]).fillna(0).astype(int)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar([LABEL_NAME[i] for i in [0,1,2]], counts.values)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Clase\")\n",
        "    plt.ylabel(\"NÂ° de registros\")\n",
        "    return save_fig_jpg(os.path.join(FIG_DIR, fname_noext))\n",
        "\n",
        "def plot_class_distribution_compare(df_des: pd.DataFrame, df_bal: pd.DataFrame, title: str, fname_noext: str):\n",
        "    c1 = df_des[LABEL_COL].value_counts().reindex([0,1,2]).fillna(0).astype(int)\n",
        "    c2 = df_bal[LABEL_COL].value_counts().reindex([0,1,2]).fillna(0).astype(int)\n",
        "\n",
        "    labels = [LABEL_NAME[i] for i in [0,1,2]]\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.bar(x - width/2, c1.values, width, label=\"Desbalanceado\")\n",
        "    plt.bar(x + width/2, c2.values, width, label=\"Balanceado\")\n",
        "    plt.xticks(x, labels)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Clase\")\n",
        "    plt.ylabel(\"NÂ° de registros\")\n",
        "    plt.legend()\n",
        "    return save_fig_jpg(os.path.join(FIG_DIR, fname_noext))\n",
        "\n",
        "# ---------------------------\n",
        "# 3) SLANG + STOPWORDS (EDA)\n",
        "# ---------------------------\n",
        "SLANG = [\n",
        "    (r\"\\bmrd\\b\", \"mierda\"),\n",
        "    (r\"\\bd\\b\", \"de\"),\n",
        "    (r\"\\b[qk]\\b\", \"que\"),\n",
        "    (r\"\\bxo\\b\", \"pero\"),\n",
        "    (r\"\\bxa\\b\", \"para\"),\n",
        "    (r\"\\b[xp]q\\b\", \"porque\"),\n",
        "    (r\"\\bes[qk]\\b\", \"es que\"),\n",
        "    (r\"\\bfvr\\b\", \"favor\"),\n",
        "    (r\"\\b(xfa|xf|pf|plis|pls|porfa)\\b\", \"por favor\"),\n",
        "    (r\"\\bdnd\\b\", \"donde\"),\n",
        "    (r\"\\btb\\b\", \"tambiÃ©n\"),\n",
        "    (r\"\\b(tq|tk)\\b\", \"te quiero\"),\n",
        "    (r\"\\b(tqm|tkm)\\b\", \"te quiero mucho\"),\n",
        "    (r\"\\bx\\b\", \"por\"),\n",
        "    (r\"\\+\", \"mas\"),\n",
        "]\n",
        "\n",
        "def apply_slang(t: str) -> str:\n",
        "    for pat, rep in SLANG:\n",
        "        t = re.sub(pat, rep, t)\n",
        "    return t\n",
        "\n",
        "stop_words = set([\n",
        "    'a','adelante','ademÃ¡s','ahi','ahora','ahÃ­','al','algo','alguna','algunas','alguno','algunos','algÃºn',\n",
        "    'alrededor','ambos','ante','anterior','antes','apenas','aproximadamente','aquel','aquellas','aquellos',\n",
        "    'aqui','aquÃ­','arriba','asi','asÃ­','atras','aunque','aÃºn','ayer','b','bajo','bastante','bien','buen',\n",
        "    'buena','buenas','bueno','buenos','cada','casi','cerca','cierta','ciertas','cierto','ciertos','cinco',\n",
        "    'como','con','contra','cosas','creo','cual','cuales','cualquier','cuando','cuanto','cuatro','cuenta',\n",
        "    'cÃ³mo','da','dado','dan','dar','de','debe','deben','debido','decir','del','demÃ¡s','dentro','desde',\n",
        "    'despuÃ©s','dia','dice','dicen','dicho','dieron','diferente','diferentes','dijeron','dijo','dio','donde',\n",
        "    'dos','durante','e','ejemplo','el','ella','ellas','ello','ellos','embargo','en','encima','entonces',\n",
        "    'entre','era','eran','eras','eres','es','esa','esas','ese','eso','esos','esta','estaba','estaban',\n",
        "    'estado','estamos','estan','estar','estarÃ¡','estas','este','esto','estos','estoy','estuvo','ex','existe',\n",
        "    'existen','fin','fue','fuera','fueron','fui','fuimos','gran','grandes','ha','haber','habÃ­a','habÃ­an',\n",
        "    'habrÃ¡','hace','hacemos','hacen','hacer','hacia','haciendo','hago','han','has','hasta','hay','haya','he',\n",
        "    'hecho','hemos','hicieron','hizo','hoy','hubo','igual','incluso','intenta','intentamos','intentan',\n",
        "    'intentar','intento','ir','junto','la','lado','largo','las','le','les','llegÃ³','lleva','llevar','lo','los',\n",
        "    'luego','lugar','manera','mas','mayor','me','mediante','mejor','menos','mi','mientras','mis','misma','mismas',\n",
        "    'mismo','mismos','modo','momento','mucha','muchas','mucho','muchos','muy','mÃ¡s','nada','nadie','ni','ninguna',\n",
        "    'ningunas','ninguno','ningunos','ningÃºn','nos','nosotras','nosotros','nuestra','nuestras','nuestro','nuestros',\n",
        "    'nueva','nuevas','nuevo','nuevos','nunca','o','ocho','otra','otras','otro','otros','para','parece','parte',\n",
        "    'pasada','pasado','pero','poca','pocas','poco','pocos','podemos','poder','podra','podrÃ¡n','podria','podrian',\n",
        "    'podrias','podrÃ­a','podrÃ­an','por','porque','posible','primer','primera','primero','primeros','principalmente',\n",
        "    'propia','propias','propio','propios','prÃ³ximo','prÃ³ximos','pudo','pueda','puede','pueden','puedo','pues','que',\n",
        "    'quien','quienes','quiere','quÃ©','quiÃ©n','respecto','se','sea','sean','segunda','segundo','segÃºn','seis','sera',\n",
        "    'serÃ¡','serÃ¡n','serÃ­a','si','sido','siempre','siendo','siete','sigue','siguiente','sin','sino','sobre','sola',\n",
        "    'solamente','solas','solo','solos','somos','son','soy','su','sus','sÃ­','tambiÃ©n','tampoco','tan','tanto','te',\n",
        "    'tendrÃ¡','tendrÃ¡n','tenemos','tener','tenga','tengo','tenÃ­a','tenido','tercera','ti','tiempo','tiene','tienen',\n",
        "    'toda','todas','todavÃ­a','todo','todos','total','tras','trata','travÃ©s','tres','tu','tus','tuvo','tuyo','un',\n",
        "    'una','unas','uno','unos','usa','usamos','usan','usar','usas','uso','usted','va','vamos','van','varias','varios',\n",
        "    'vaya','veces','ven','ver','verdad','vez','vosotras','vosotros','voy','y','ya','yo',\n",
        "    'Ã¡','Ã©sta','Ã©ste','Ã©stas','Ã©stos','Ãºltima','Ãºltimas','ultimo','Ãºltimo','Ãºltimos'\n",
        "])\n",
        "\n",
        "# ---------------------------\n",
        "# 4) NormalizaciÃ³n\n",
        "# ---------------------------\n",
        "def normalize_for_transformer(text: str) -> str:\n",
        "    # Suave (con tildes/Ã±/Ã¼) para entrenamiento\n",
        "    t = fix_text_utf8(text).lower()\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\w+\", \" \", t)\n",
        "    t = re.sub(r\"#\\w+\", \" \", t)\n",
        "    t = apply_slang(t)\n",
        "    t = re.sub(r\"[^a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "def eda_aggressive(text: str) -> str:\n",
        "    # Agresivo (sin tildes, stopwords fuera) SOLO para EDA\n",
        "    t = fix_text_utf8(text).lower()\n",
        "    t = apply_slang(t)\n",
        "    t = remove_accents(t)\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\w+\", \" \", t)\n",
        "    t = re.sub(r\"#\\w+\", \" \", t)\n",
        "    t = re.sub(r\"[^a-zÃ±\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    toks = [w for w in t.split() if (len(w) > 2 and w not in stop_words)]\n",
        "    return \" \".join(toks)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) TOP 20 GENERAL (EDA normalizado: text_eda)\n",
        "# ---------------------------\n",
        "def tfidf_top_general(df_in: pd.DataFrame, text_col=\"text_eda\", top_n=20, ngram_range=(1,2), min_df=3):\n",
        "    texts = df_in[text_col].astype(str).tolist()\n",
        "    vec = TfidfVectorizer(lowercase=True, ngram_range=ngram_range, min_df=min_df)\n",
        "    X = vec.fit_transform(texts)\n",
        "    terms = np.array(vec.get_feature_names_out())\n",
        "\n",
        "    mean_tfidf = np.asarray(X.mean(axis=0)).ravel()\n",
        "    order = np.argsort(mean_tfidf)[::-1]\n",
        "\n",
        "    picked = []\n",
        "    for j in order:\n",
        "        term = terms[j]\n",
        "        if term_allowed_for_tfidf(term):\n",
        "            picked.append((term, float(mean_tfidf[j])))\n",
        "        if len(picked) >= top_n:\n",
        "            break\n",
        "    return picked\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Splits + HF datasets\n",
        "# ---------------------------\n",
        "def split_stratified(df_in: pd.DataFrame, label_col: str, test_size=0.15, val_size=0.15, seed=42):\n",
        "    df_train, df_temp = train_test_split(\n",
        "        df_in, test_size=(test_size + val_size),\n",
        "        stratify=df_in[label_col], random_state=seed\n",
        "    )\n",
        "    rel_test = test_size / (test_size + val_size)\n",
        "    df_val, df_test = train_test_split(\n",
        "        df_temp, test_size=rel_test,\n",
        "        stratify=df_temp[label_col], random_state=seed\n",
        "    )\n",
        "    return df_train.reset_index(drop=True), df_val.reset_index(drop=True), df_test.reset_index(drop=True)\n",
        "\n",
        "def make_balanced_undersampling(df_in: pd.DataFrame, label_col: str, seed=42) -> pd.DataFrame:\n",
        "    counts = df_in[label_col].value_counts()\n",
        "    n_min = counts.min()\n",
        "    parts = []\n",
        "    for lab in sorted(counts.index):\n",
        "        parts.append(df_in[df_in[label_col] == lab].sample(n=n_min, random_state=seed))\n",
        "    return pd.concat(parts).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "def tokenize_dataset(ds: DatasetDict, tokenizer, text_col: str):\n",
        "    def tok(batch):\n",
        "        return tokenizer(batch[text_col], truncation=True, max_length=MAX_LEN)\n",
        "    return ds.map(tok, batched=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 7) MÃ©tricas (HF Evaluate)\n",
        "# ---------------------------\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"precision_macro\": precision_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
        "        \"recall_macro\": recall_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
        "    }\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Figuras: Loss + ROC + CM\n",
        "# ---------------------------\n",
        "def plot_loss_curves(trainer, title, fname_noext):\n",
        "    hist = trainer.state.log_history\n",
        "    train_steps, train_loss = [], []\n",
        "    eval_steps, eval_loss = [], []\n",
        "\n",
        "    for row in hist:\n",
        "        if \"loss\" in row and \"eval_loss\" not in row and \"step\" in row:\n",
        "            train_steps.append(row[\"step\"])\n",
        "            train_loss.append(row[\"loss\"])\n",
        "        if \"eval_loss\" in row and \"step\" in row:\n",
        "            eval_steps.append(row[\"step\"])\n",
        "            eval_loss.append(row[\"eval_loss\"])\n",
        "\n",
        "    if len(train_steps)==0 and len(eval_steps)==0:\n",
        "        return None\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    if len(train_steps)>0:\n",
        "        plt.plot(train_steps, train_loss, label=\"train_loss\")\n",
        "    if len(eval_steps)>0:\n",
        "        plt.plot(eval_steps, eval_loss, label=\"eval_loss\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    return save_fig_jpg(os.path.join(FIG_DIR, fname_noext))\n",
        "\n",
        "def plot_confusion_matrix_blue(cm, title, fname_noext):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(3)\n",
        "    plt.xticks(tick_marks, [LABEL_NAME[i] for i in [0,1,2]])\n",
        "    plt.yticks(tick_marks, [LABEL_NAME[i] for i in [0,1,2]])\n",
        "    thresh = cm.max()/2.0 if cm.max()>0 else 0.5\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            plt.text(j, i, int(cm[i,j]),\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if cm[i,j] > thresh else \"black\",\n",
        "                     fontsize=12, fontweight=\"bold\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.xlabel(\"PredicciÃ³n\")\n",
        "    return save_fig_jpg(os.path.join(FIG_DIR, fname_noext))\n",
        "\n",
        "def plot_multiclass_roc(y_true, y_proba, title, fname_noext):\n",
        "    classes = [0,1,2]\n",
        "    y_bin = label_binarize(y_true, classes=classes)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, lab in enumerate(classes):\n",
        "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{LABEL_NAME[lab]} (AUC={roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_bin.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", label=f\"micro-avg (AUC={auc_micro:.3f})\")\n",
        "    plt.plot([0,1],[0,1], linestyle=\":\", linewidth=1)\n",
        "    plt.xlim([0.0,1.0]); plt.ylim([0.0,1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    return save_fig_jpg(os.path.join(FIG_DIR, fname_noext))\n",
        "\n",
        "# ---------------------------\n",
        "# 9) Carga tokenizer/modelo (ALBETO preferir use_fast=False)\n",
        "# ---------------------------\n",
        "def load_tokenizer_and_model(model_ckpt: str):\n",
        "    is_albert = \"albert\" in model_ckpt.lower()\n",
        "    preferred_fast = (not is_albert)\n",
        "    last_err = None\n",
        "    for use_fast in [preferred_fast, (not preferred_fast)]:\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=use_fast)\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                model_ckpt,\n",
        "                num_labels=3,\n",
        "                id2label={i: LABEL_NAME[i] for i in [0,1,2]},\n",
        "                label2id={LABEL_NAME[i]: i for i in [0,1,2]},\n",
        "            )\n",
        "            return tokenizer, model, use_fast, \"OK\"\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    return None, None, None, f\"FAIL: {last_err}\"\n",
        "\n",
        "# ---------------------------\n",
        "# 10) Entrenar \"como antes\" + NUEVO: loss en resultados\n",
        "# ---------------------------\n",
        "def train_and_eval_keep_behavior(scenario_name: str, model_name_key: str, model_ckpt: str, ds: DatasetDict):\n",
        "    clear_gpu()\n",
        "\n",
        "    tokenizer, model, used_fast, status = load_tokenizer_and_model(model_ckpt)\n",
        "    if tokenizer is None:\n",
        "        return {\n",
        "            \"scenario\": scenario_name, \"model\": model_name_key, \"status\": status,\n",
        "            \"accuracy\": np.nan, \"f1_macro\": np.nan, \"precision_macro\": np.nan, \"recall_macro\": np.nan,\n",
        "            \"auc_macro_ovr\": np.nan, \"test_loss\": np.nan, \"best_val_loss\": np.nan, \"best_val_f1_macro\": np.nan\n",
        "        }\n",
        "\n",
        "    ds_tok = tokenize_dataset(ds, tokenizer, TEXT_FOR_TRAIN)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    run_dir = os.path.join(CKPT_ROOT, f\"{scenario_name}_{model_name_key}\")\n",
        "    if os.path.exists(run_dir):\n",
        "        shutil.rmtree(run_dir, ignore_errors=True)\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=run_dir,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        learning_rate=LR,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRAD_ACC,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        seed=SEED,\n",
        "        fp16=USE_FP16,\n",
        "        remove_unused_columns=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=ds_tok[\"train\"],\n",
        "        eval_dataset=ds_tok[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # âœ… curva de pÃ©rdida (train/eval)\n",
        "    plot_loss_curves(\n",
        "        trainer,\n",
        "        f\"Loss - {model_name_key} ({scenario_name})\",\n",
        "        f\"TFM_LOSS_{scenario_name}_{model_name_key}\"\n",
        "    )\n",
        "\n",
        "    # âœ… extraer best_val_loss y best_val_f1_macro desde log_history (validaciÃ³n)\n",
        "    hist = trainer.state.log_history\n",
        "    eval_losses = [h[\"eval_loss\"] for h in hist if \"eval_loss\" in h]\n",
        "    eval_f1s = [h.get(\"eval_f1_macro\") for h in hist if \"eval_f1_macro\" in h]\n",
        "\n",
        "    best_val_loss = float(np.min(eval_losses)) if len(eval_losses) else np.nan\n",
        "    best_val_f1 = float(np.max([x for x in eval_f1s if x is not None])) if len(eval_f1s) else np.nan\n",
        "\n",
        "    # Test\n",
        "    test_metrics = trainer.evaluate(ds_tok[\"test\"])\n",
        "    preds_out = trainer.predict(ds_tok[\"test\"])\n",
        "\n",
        "    y_true = preds_out.label_ids\n",
        "    y_pred = np.argmax(preds_out.predictions, axis=-1)\n",
        "\n",
        "    # CM\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "    plot_confusion_matrix_blue(\n",
        "        cm,\n",
        "        f\"Matriz de confusiÃ³n - {model_name_key} ({scenario_name})\",\n",
        "        f\"TFM_CM_{scenario_name}_{model_name_key}\"\n",
        "    )\n",
        "\n",
        "    # ROC\n",
        "    logits = preds_out.predictions\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    plot_multiclass_roc(\n",
        "        y_true, probs,\n",
        "        f\"ROC - {model_name_key} ({scenario_name})\",\n",
        "        f\"TFM_ROC_{scenario_name}_{model_name_key}\"\n",
        "    )\n",
        "\n",
        "    # AUC macro OVR\n",
        "    try:\n",
        "        y_bin = label_binarize(y_true, classes=[0,1,2])\n",
        "        auc_macro = roc_auc_score(y_bin, probs, average=\"macro\", multi_class=\"ovr\")\n",
        "    except Exception:\n",
        "        auc_macro = np.nan\n",
        "\n",
        "    # âœ… BORRAR checkpoints\n",
        "    shutil.rmtree(run_dir, ignore_errors=True)\n",
        "\n",
        "    return {\n",
        "        \"scenario\": scenario_name,\n",
        "        \"model\": model_name_key,\n",
        "        \"accuracy\": float(test_metrics.get(\"eval_accuracy\", np.nan)),\n",
        "        \"f1_macro\": float(test_metrics.get(\"eval_f1_macro\", np.nan)),\n",
        "        \"precision_macro\": float(test_metrics.get(\"eval_precision_macro\", np.nan)),\n",
        "        \"recall_macro\": float(test_metrics.get(\"eval_recall_macro\", np.nan)),\n",
        "        \"auc_macro_ovr\": float(auc_macro),\n",
        "        \"test_loss\": float(test_metrics.get(\"eval_loss\", np.nan)),   # âœ… NUEVO\n",
        "        \"best_val_loss\": best_val_loss,                               # âœ… NUEVO\n",
        "        \"best_val_f1_macro\": best_val_f1,                             # âœ… NUEVO\n",
        "        \"tokenizer_use_fast\": bool(used_fast),\n",
        "        \"status\": \"OK\"\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# A) CARGAR DATASET\n",
        "# ============================================================\n",
        "if os.path.exists(LOCAL_CSV):\n",
        "    print(f\"ðŸ“¥ Leyendo CSV local: {LOCAL_CSV}\")\n",
        "    df_base = pd.read_csv(LOCAL_CSV)\n",
        "else:\n",
        "    print(\"ðŸ“¥ CSV local no encontrado. Leyendo GitHub RAW...\")\n",
        "    df_base = pd.read_csv(GITHUB_RAW_URL)\n",
        "\n",
        "assert TEXT_COL in df_base.columns, f\"Falta columna: {TEXT_COL}\"\n",
        "assert LABEL_COL in df_base.columns, f\"Falta columna: {LABEL_COL}\"\n",
        "\n",
        "df_base = df_base[[TEXT_COL, LABEL_COL]].copy()\n",
        "df_base[TEXT_COL] = df_base[TEXT_COL].fillna(\"\").astype(str).str.strip()\n",
        "df_base = df_base[df_base[TEXT_COL].str.len() > 0]\n",
        "\n",
        "df_base[LABEL_COL] = pd.to_numeric(df_base[LABEL_COL], errors=\"coerce\")\n",
        "df_base = df_base.dropna(subset=[LABEL_COL])\n",
        "df_base[LABEL_COL] = df_base[LABEL_COL].astype(int)\n",
        "df_base = df_base[df_base[LABEL_COL].isin(VALID_LABELS)].reset_index(drop=True)\n",
        "\n",
        "df_base = df_base.drop_duplicates(subset=[TEXT_COL]).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ… Total registros vÃ¡lidos (base): {len(df_base)}\")\n",
        "\n",
        "# Columnas\n",
        "df_base[\"text_tr\"] = df_base[TEXT_COL].apply(normalize_for_transformer)\n",
        "df_base[\"text_eda\"] = df_base[TEXT_COL].apply(eda_aggressive)\n",
        "df_base[\"label_name\"] = df_base[LABEL_COL].map(LABEL_NAME)\n",
        "\n",
        "# ============================================================\n",
        "# B0) Construir ambos datasets (para los 3 grÃ¡ficos de distribuciÃ³n)\n",
        "# ============================================================\n",
        "df_des = df_base.copy()\n",
        "df_bal = make_balanced_undersampling(df_base, LABEL_COL, seed=SEED)\n",
        "\n",
        "# âœ… 1) DistribuciÃ³n balanceado\n",
        "plot_class_distribution(\n",
        "    df_bal,\n",
        "    \"DistribuciÃ³n de clases - dataset balanceado\",\n",
        "    \"TFM_02_Distribucion_Clases_balanceado\"\n",
        ")\n",
        "\n",
        "# âœ… 2) DistribuciÃ³n desbalanceado\n",
        "plot_class_distribution(\n",
        "    df_des,\n",
        "    \"DistribuciÃ³n de clases - dataset desbalanceado\",\n",
        "    \"TFM_01_Distribucion_Clases_desbalanceado\"\n",
        ")\n",
        "\n",
        "# âœ… 3) Comparativo (nombre EXACTO como tu Cap. 4)\n",
        "plot_class_distribution_compare(\n",
        "    df_des, df_bal,\n",
        "    \"DistribuciÃ³n de clases en el dataset desbalanceado y balanceado\",\n",
        "    \"TFM_03_Comp_Distribucion_Desbalanceado_vs_Balanceado\"\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# B) Ejecutar escenarios: TOP 20 + WordCloud + conteos + entrenamiento\n",
        "# ============================================================\n",
        "all_metrics = []\n",
        "train_counts_rows = []\n",
        "\n",
        "for sc in SCENARIOS:\n",
        "    scenario_name = sc[\"name\"]\n",
        "    is_balanced = sc[\"balanced\"]\n",
        "\n",
        "    df_sc = df_bal.copy() if is_balanced else df_des.copy()\n",
        "\n",
        "    # Splits\n",
        "    train_df, val_df, test_df = split_stratified(df_sc, LABEL_COL, test_size=TEST_SIZE, val_size=VAL_SIZE, seed=SEED)\n",
        "\n",
        "    # âœ… Conteo de registros usados\n",
        "    train_counts_rows.append({\n",
        "        \"scenario\": scenario_name,\n",
        "        \"balanced\": is_balanced,\n",
        "        \"total_escenario\": len(df_sc),\n",
        "        \"train_usado_entrenamiento\": len(train_df),\n",
        "        \"validation\": len(val_df),\n",
        "        \"test\": len(test_df),\n",
        "    })\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ESCENARIO: {scenario_name.upper()} | balanced={is_balanced}\")\n",
        "    print(f\"Total escenario: {len(df_sc)} | Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # âœ… WordCloud general (EDA) - nombres como tu TFM\n",
        "    joined = \" \".join(df_sc[\"text_eda\"].astype(str).tolist()).strip()\n",
        "    if joined:\n",
        "        wc = WordCloud(width=1200, height=600, background_color=\"white\").generate(joined)\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.imshow(wc, interpolation=\"bilinear\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"WordCloud general (EDA) - {scenario_name}\")\n",
        "        save_fig_jpg(os.path.join(FIG_DIR, f\"TFM_04_WordCloud_General_{scenario_name}\"))\n",
        "\n",
        "    # âœ… TOP 20 general TF-IDF (EDA)\n",
        "    top_general = tfidf_top_general(df_sc, text_col=\"text_eda\", top_n=20)\n",
        "    df_top_general = pd.DataFrame(top_general, columns=[\"termino\", \"tfidf_mean\"])\n",
        "\n",
        "    topgen_csv = os.path.join(TAB_DIR, f\"TFM_TFIDF_Top20_General_{scenario_name}.csv\")\n",
        "    topgen_md  = os.path.join(TAB_DIR, f\"TFM_TFIDF_Top20_General_{scenario_name}.md\")\n",
        "    df_top_general.to_csv(topgen_csv, index=False, encoding=\"utf-8\")\n",
        "    save_markdown_table(df_top_general, topgen_md, f\"TFM - TF-IDF Top 20 General (EDA) - {scenario_name}\")\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.bar(df_top_general[\"termino\"], df_top_general[\"tfidf_mean\"])\n",
        "    plt.title(f\"TF-IDF Top 20 General (EDA) - {scenario_name}\")\n",
        "    plt.xticks(rotation=75, ha=\"right\")\n",
        "    save_fig_jpg(os.path.join(FIG_DIR, f\"TFM_08_TFIDF_Top20_General_{scenario_name}\"))\n",
        "\n",
        "    # Entrenamiento\n",
        "    ds = DatasetDict(\n",
        "        train=Dataset.from_pandas(train_df[[LABEL_COL, TEXT_FOR_TRAIN]].reset_index(drop=True)),\n",
        "        validation=Dataset.from_pandas(val_df[[LABEL_COL, TEXT_FOR_TRAIN]].reset_index(drop=True)),\n",
        "        test=Dataset.from_pandas(test_df[[LABEL_COL, TEXT_FOR_TRAIN]].reset_index(drop=True)),\n",
        "    )\n",
        "\n",
        "    for model_key, ckpt in MODELS.items():\n",
        "        res = train_and_eval_keep_behavior(scenario_name, model_key, ckpt, ds)\n",
        "        all_metrics.append(res)\n",
        "\n",
        "# ============================================================\n",
        "# C) Guardar tabla de conteos (CSV + MD)\n",
        "# ============================================================\n",
        "df_counts = pd.DataFrame(train_counts_rows)\n",
        "counts_csv = os.path.join(TAB_DIR, \"TFM_Conteo_Registros_Entrenamiento_Escenarios.csv\")\n",
        "counts_md  = os.path.join(TAB_DIR, \"TFM_Conteo_Registros_Entrenamiento_Escenarios.md\")\n",
        "df_counts.to_csv(counts_csv, index=False, encoding=\"utf-8\")\n",
        "save_markdown_table(df_counts, counts_md, \"TFM - Registros usados en entrenamiento por escenario\")\n",
        "\n",
        "# ============================================================\n",
        "# D) Guardar tabla final de mÃ©tricas + LOSS (CSV + MD)\n",
        "# ============================================================\n",
        "df_metrics = pd.DataFrame(all_metrics)\n",
        "df_metrics = df_metrics[\n",
        "    [\"scenario\",\"model\",\n",
        "     \"accuracy\",\"f1_macro\",\"precision_macro\",\"recall_macro\",\"auc_macro_ovr\",\n",
        "     \"test_loss\",\"best_val_loss\",\"best_val_f1_macro\",   # âœ… NUEVO\n",
        "     \"tokenizer_use_fast\",\"status\"]\n",
        "].sort_values(by=[\"scenario\",\"f1_macro\"], ascending=[True, False])\n",
        "\n",
        "metrics_csv = os.path.join(TAB_DIR, \"TFM_Metricas_Comparativa_Modelos.csv\")\n",
        "metrics_md  = os.path.join(TAB_DIR, \"TFM_Metricas_Comparativa_Modelos.md\")\n",
        "df_metrics.to_csv(metrics_csv, index=False, encoding=\"utf-8\")\n",
        "save_markdown_table(df_metrics, metrics_md, \"TFM - MÃ©tricas comparativas (modelos x escenarios) + LOSS\")\n",
        "\n",
        "print(\"\\nâœ… Tablas guardadas en:\", TAB_DIR)\n",
        "print(\"âœ… Figuras guardadas en:\", FIG_DIR)\n",
        "\n",
        "# ============================================================\n",
        "# E) ZIP SOLO con tablas y Figuras (NO checkpoints)\n",
        "# ============================================================\n",
        "zip_path = os.path.join(\"/content\", ZIP_NAME)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for folder in [FIG_DIR, TAB_DIR]:\n",
        "        for root, dirs, files in os.walk(folder):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                rel_path = os.path.relpath(full_path, BASE_OUTPUT_DIR)\n",
        "                z.write(full_path, arcname=os.path.join(\"outputs_tfm_solo_tablas_figuras\", rel_path))\n",
        "\n",
        "print(f\"\\nâœ… ZIP (solo tablas+figuras) listo: {zip_path}\")\n",
        "\n",
        "# limpieza final de checkpoints\n",
        "shutil.rmtree(CKPT_ROOT, ignore_errors=True)\n",
        "os.makedirs(CKPT_ROOT, exist_ok=True)\n",
        "\n",
        "# Descarga automÃ¡tica en Colab\n",
        "from google.colab import files\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "29fuNi14qFoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}